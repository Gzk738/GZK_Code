{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07bb943-8d3a-46de-bd61-c8c939441cf2",
   "metadata": {},
   "source": [
    "# 这是bert每层的名字\n",
    "bert.embeddings.position_ids\n",
    "bert.embeddings.word_embeddings.weight\n",
    "bert.embeddings.position_embeddings.weight\n",
    "bert.embeddings.token_type_embeddings.weight\n",
    "bert.embeddings.LayerNorm.weight\n",
    "bert.embeddings.LayerNorm.bias\n",
    "bert.encoder.layer.0.attention.self.query.weight\n",
    "bert.encoder.layer.0.attention.self.query.bias\n",
    "bert.encoder.layer.0.attention.self.key.weight\n",
    "bert.encoder.layer.0.attention.self.key.bias\n",
    "bert.encoder.layer.0.attention.self.value.weight\n",
    "bert.encoder.layer.0.attention.self.value.bias\n",
    "bert.encoder.layer.0.attention.output.dense.weight\n",
    "bert.encoder.layer.0.attention.output.dense.bias\n",
    "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.0.intermediate.dense.weight\n",
    "bert.encoder.layer.0.intermediate.dense.bias\n",
    "bert.encoder.layer.0.output.dense.weight\n",
    "bert.encoder.layer.0.output.dense.bias\n",
    "bert.encoder.layer.0.output.LayerNorm.weight\n",
    "bert.encoder.layer.0.output.LayerNorm.bias\n",
    "bert.encoder.layer.1.attention.self.query.weight\n",
    "bert.encoder.layer.1.attention.self.query.bias\n",
    "bert.encoder.layer.1.attention.self.key.weight\n",
    "bert.encoder.layer.1.attention.self.key.bias\n",
    "bert.encoder.layer.1.attention.self.value.weight\n",
    "bert.encoder.layer.1.attention.self.value.bias\n",
    "bert.encoder.layer.1.attention.output.dense.weight\n",
    "bert.encoder.layer.1.attention.output.dense.bias\n",
    "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.1.intermediate.dense.weight\n",
    "bert.encoder.layer.1.intermediate.dense.bias\n",
    "bert.encoder.layer.1.output.dense.weight\n",
    "bert.encoder.layer.1.output.dense.bias\n",
    "bert.encoder.layer.1.output.LayerNorm.weight\n",
    "bert.encoder.layer.1.output.LayerNorm.bias\n",
    "bert.encoder.layer.2.attention.self.query.weight\n",
    "bert.encoder.layer.2.attention.self.query.bias\n",
    "bert.encoder.layer.2.attention.self.key.weight\n",
    "bert.encoder.layer.2.attention.self.key.bias\n",
    "bert.encoder.layer.2.attention.self.value.weight\n",
    "bert.encoder.layer.2.attention.self.value.bias\n",
    "bert.encoder.layer.2.attention.output.dense.weight\n",
    "bert.encoder.layer.2.attention.output.dense.bias\n",
    "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.2.intermediate.dense.weight\n",
    "bert.encoder.layer.2.intermediate.dense.bias\n",
    "bert.encoder.layer.2.output.dense.weight\n",
    "bert.encoder.layer.2.output.dense.bias\n",
    "bert.encoder.layer.2.output.LayerNorm.weight\n",
    "bert.encoder.layer.2.output.LayerNorm.bias\n",
    "bert.encoder.layer.3.attention.self.query.weight\n",
    "bert.encoder.layer.3.attention.self.query.bias\n",
    "bert.encoder.layer.3.attention.self.key.weight\n",
    "bert.encoder.layer.3.attention.self.key.bias\n",
    "bert.encoder.layer.3.attention.self.value.weight\n",
    "bert.encoder.layer.3.attention.self.value.bias\n",
    "bert.encoder.layer.3.attention.output.dense.weight\n",
    "bert.encoder.layer.3.attention.output.dense.bias\n",
    "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.3.intermediate.dense.weight\n",
    "bert.encoder.layer.3.intermediate.dense.bias\n",
    "bert.encoder.layer.3.output.dense.weight\n",
    "bert.encoder.layer.3.output.dense.bias\n",
    "bert.encoder.layer.3.output.LayerNorm.weight\n",
    "bert.encoder.layer.3.output.LayerNorm.bias\n",
    "bert.encoder.layer.4.attention.self.query.weight\n",
    "bert.encoder.layer.4.attention.self.query.bias\n",
    "bert.encoder.layer.4.attention.self.key.weight\n",
    "bert.encoder.layer.4.attention.self.key.bias\n",
    "bert.encoder.layer.4.attention.self.value.weight\n",
    "bert.encoder.layer.4.attention.self.value.bias\n",
    "bert.encoder.layer.4.attention.output.dense.weight\n",
    "bert.encoder.layer.4.attention.output.dense.bias\n",
    "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.4.intermediate.dense.weight\n",
    "bert.encoder.layer.4.intermediate.dense.bias\n",
    "bert.encoder.layer.4.output.dense.weight\n",
    "bert.encoder.layer.4.output.dense.bias\n",
    "bert.encoder.layer.4.output.LayerNorm.weight\n",
    "bert.encoder.layer.4.output.LayerNorm.bias\n",
    "bert.encoder.layer.5.attention.self.query.weight\n",
    "bert.encoder.layer.5.attention.self.query.bias\n",
    "bert.encoder.layer.5.attention.self.key.weight\n",
    "bert.encoder.layer.5.attention.self.key.bias\n",
    "bert.encoder.layer.5.attention.self.value.weight\n",
    "bert.encoder.layer.5.attention.self.value.bias\n",
    "bert.encoder.layer.5.attention.output.dense.weight\n",
    "bert.encoder.layer.5.attention.output.dense.bias\n",
    "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.5.intermediate.dense.weight\n",
    "bert.encoder.layer.5.intermediate.dense.bias\n",
    "bert.encoder.layer.5.output.dense.weight\n",
    "bert.encoder.layer.5.output.dense.bias\n",
    "bert.encoder.layer.5.output.LayerNorm.weight\n",
    "bert.encoder.layer.5.output.LayerNorm.bias\n",
    "bert.encoder.layer.6.attention.self.query.weight\n",
    "bert.encoder.layer.6.attention.self.query.bias\n",
    "bert.encoder.layer.6.attention.self.key.weight\n",
    "bert.encoder.layer.6.attention.self.key.bias\n",
    "bert.encoder.layer.6.attention.self.value.weight\n",
    "bert.encoder.layer.6.attention.self.value.bias\n",
    "bert.encoder.layer.6.attention.output.dense.weight\n",
    "bert.encoder.layer.6.attention.output.dense.bias\n",
    "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.6.intermediate.dense.weight\n",
    "bert.encoder.layer.6.intermediate.dense.bias\n",
    "bert.encoder.layer.6.output.dense.weight\n",
    "bert.encoder.layer.6.output.dense.bias\n",
    "bert.encoder.layer.6.output.LayerNorm.weight\n",
    "bert.encoder.layer.6.output.LayerNorm.bias\n",
    "bert.encoder.layer.7.attention.self.query.weight\n",
    "bert.encoder.layer.7.attention.self.query.bias\n",
    "bert.encoder.layer.7.attention.self.key.weight\n",
    "bert.encoder.layer.7.attention.self.key.bias\n",
    "bert.encoder.layer.7.attention.self.value.weight\n",
    "bert.encoder.layer.7.attention.self.value.bias\n",
    "bert.encoder.layer.7.attention.output.dense.weight\n",
    "bert.encoder.layer.7.attention.output.dense.bias\n",
    "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.7.intermediate.dense.weight\n",
    "bert.encoder.layer.7.intermediate.dense.bias\n",
    "bert.encoder.layer.7.output.dense.weight\n",
    "bert.encoder.layer.7.output.dense.bias\n",
    "bert.encoder.layer.7.output.LayerNorm.weight\n",
    "bert.encoder.layer.7.output.LayerNorm.bias\n",
    "bert.encoder.layer.8.attention.self.query.weight\n",
    "bert.encoder.layer.8.attention.self.query.bias\n",
    "bert.encoder.layer.8.attention.self.key.weight\n",
    "bert.encoder.layer.8.attention.self.key.bias\n",
    "bert.encoder.layer.8.attention.self.value.weight\n",
    "bert.encoder.layer.8.attention.self.value.bias\n",
    "bert.encoder.layer.8.attention.output.dense.weight\n",
    "bert.encoder.layer.8.attention.output.dense.bias\n",
    "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.8.intermediate.dense.weight\n",
    "bert.encoder.layer.8.intermediate.dense.bias\n",
    "bert.encoder.layer.8.output.dense.weight\n",
    "bert.encoder.layer.8.output.dense.bias\n",
    "bert.encoder.layer.8.output.LayerNorm.weight\n",
    "bert.encoder.layer.8.output.LayerNorm.bias\n",
    "bert.encoder.layer.9.attention.self.query.weight\n",
    "bert.encoder.layer.9.attention.self.query.bias\n",
    "bert.encoder.layer.9.attention.self.key.weight\n",
    "bert.encoder.layer.9.attention.self.key.bias\n",
    "bert.encoder.layer.9.attention.self.value.weight\n",
    "bert.encoder.layer.9.attention.self.value.bias\n",
    "bert.encoder.layer.9.attention.output.dense.weight\n",
    "bert.encoder.layer.9.attention.output.dense.bias\n",
    "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.9.intermediate.dense.weight\n",
    "bert.encoder.layer.9.intermediate.dense.bias\n",
    "bert.encoder.layer.9.output.dense.weight\n",
    "bert.encoder.layer.9.output.dense.bias\n",
    "bert.encoder.layer.9.output.LayerNorm.weight\n",
    "bert.encoder.layer.9.output.LayerNorm.bias\n",
    "bert.encoder.layer.10.attention.self.query.weight\n",
    "bert.encoder.layer.10.attention.self.query.bias\n",
    "bert.encoder.layer.10.attention.self.key.weight\n",
    "bert.encoder.layer.10.attention.self.key.bias\n",
    "bert.encoder.layer.10.attention.self.value.weight\n",
    "bert.encoder.layer.10.attention.self.value.bias\n",
    "bert.encoder.layer.10.attention.output.dense.weight\n",
    "bert.encoder.layer.10.attention.output.dense.bias\n",
    "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.10.intermediate.dense.weight\n",
    "bert.encoder.layer.10.intermediate.dense.bias\n",
    "bert.encoder.layer.10.output.dense.weight\n",
    "bert.encoder.layer.10.output.dense.bias\n",
    "bert.encoder.layer.10.output.LayerNorm.weight\n",
    "bert.encoder.layer.10.output.LayerNorm.bias\n",
    "bert.encoder.layer.11.attention.self.query.weight\n",
    "bert.encoder.layer.11.attention.self.query.bias\n",
    "bert.encoder.layer.11.attention.self.key.weight\n",
    "bert.encoder.layer.11.attention.self.key.bias\n",
    "bert.encoder.layer.11.attention.self.value.weight\n",
    "bert.encoder.layer.11.attention.self.value.bias\n",
    "bert.encoder.layer.11.attention.output.dense.weight\n",
    "bert.encoder.layer.11.attention.output.dense.bias\n",
    "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.11.intermediate.dense.weight\n",
    "bert.encoder.layer.11.intermediate.dense.bias\n",
    "bert.encoder.layer.11.output.dense.weight\n",
    "bert.encoder.layer.11.output.dense.bias\n",
    "bert.encoder.layer.11.output.LayerNorm.weight\n",
    "bert.encoder.layer.11.output.LayerNorm.bias\n",
    "bert.encoder.layer.12.attention.self.query.weight\n",
    "bert.encoder.layer.12.attention.self.query.bias\n",
    "bert.encoder.layer.12.attention.self.key.weight\n",
    "bert.encoder.layer.12.attention.self.key.bias\n",
    "bert.encoder.layer.12.attention.self.value.weight\n",
    "bert.encoder.layer.12.attention.self.value.bias\n",
    "bert.encoder.layer.12.attention.output.dense.weight\n",
    "bert.encoder.layer.12.attention.output.dense.bias\n",
    "bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.12.intermediate.dense.weight\n",
    "bert.encoder.layer.12.intermediate.dense.bias\n",
    "bert.encoder.layer.12.output.dense.weight\n",
    "bert.encoder.layer.12.output.dense.bias\n",
    "bert.encoder.layer.12.output.LayerNorm.weight\n",
    "bert.encoder.layer.12.output.LayerNorm.bias\n",
    "bert.encoder.layer.13.attention.self.query.weight\n",
    "bert.encoder.layer.13.attention.self.query.bias\n",
    "bert.encoder.layer.13.attention.self.key.weight\n",
    "bert.encoder.layer.13.attention.self.key.bias\n",
    "bert.encoder.layer.13.attention.self.value.weight\n",
    "bert.encoder.layer.13.attention.self.value.bias\n",
    "bert.encoder.layer.13.attention.output.dense.weight\n",
    "bert.encoder.layer.13.attention.output.dense.bias\n",
    "bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.13.intermediate.dense.weight\n",
    "bert.encoder.layer.13.intermediate.dense.bias\n",
    "bert.encoder.layer.13.output.dense.weight\n",
    "bert.encoder.layer.13.output.dense.bias\n",
    "bert.encoder.layer.13.output.LayerNorm.weight\n",
    "bert.encoder.layer.13.output.LayerNorm.bias\n",
    "bert.encoder.layer.14.attention.self.query.weight\n",
    "bert.encoder.layer.14.attention.self.query.bias\n",
    "bert.encoder.layer.14.attention.self.key.weight\n",
    "bert.encoder.layer.14.attention.self.key.bias\n",
    "bert.encoder.layer.14.attention.self.value.weight\n",
    "bert.encoder.layer.14.attention.self.value.bias\n",
    "bert.encoder.layer.14.attention.output.dense.weight\n",
    "bert.encoder.layer.14.attention.output.dense.bias\n",
    "bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.14.intermediate.dense.weight\n",
    "bert.encoder.layer.14.intermediate.dense.bias\n",
    "bert.encoder.layer.14.output.dense.weight\n",
    "bert.encoder.layer.14.output.dense.bias\n",
    "bert.encoder.layer.14.output.LayerNorm.weight\n",
    "bert.encoder.layer.14.output.LayerNorm.bias\n",
    "bert.encoder.layer.15.attention.self.query.weight\n",
    "bert.encoder.layer.15.attention.self.query.bias\n",
    "bert.encoder.layer.15.attention.self.key.weight\n",
    "bert.encoder.layer.15.attention.self.key.bias\n",
    "bert.encoder.layer.15.attention.self.value.weight\n",
    "bert.encoder.layer.15.attention.self.value.bias\n",
    "bert.encoder.layer.15.attention.output.dense.weight\n",
    "bert.encoder.layer.15.attention.output.dense.bias\n",
    "bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.15.intermediate.dense.weight\n",
    "bert.encoder.layer.15.intermediate.dense.bias\n",
    "bert.encoder.layer.15.output.dense.weight\n",
    "bert.encoder.layer.15.output.dense.bias\n",
    "bert.encoder.layer.15.output.LayerNorm.weight\n",
    "bert.encoder.layer.15.output.LayerNorm.bias\n",
    "bert.encoder.layer.16.attention.self.query.weight\n",
    "bert.encoder.layer.16.attention.self.query.bias\n",
    "bert.encoder.layer.16.attention.self.key.weight\n",
    "bert.encoder.layer.16.attention.self.key.bias\n",
    "bert.encoder.layer.16.attention.self.value.weight\n",
    "bert.encoder.layer.16.attention.self.value.bias\n",
    "bert.encoder.layer.16.attention.output.dense.weight\n",
    "bert.encoder.layer.16.attention.output.dense.bias\n",
    "bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.16.intermediate.dense.weight\n",
    "bert.encoder.layer.16.intermediate.dense.bias\n",
    "bert.encoder.layer.16.output.dense.weight\n",
    "bert.encoder.layer.16.output.dense.bias\n",
    "bert.encoder.layer.16.output.LayerNorm.weight\n",
    "bert.encoder.layer.16.output.LayerNorm.bias\n",
    "bert.encoder.layer.17.attention.self.query.weight\n",
    "bert.encoder.layer.17.attention.self.query.bias\n",
    "bert.encoder.layer.17.attention.self.key.weight\n",
    "bert.encoder.layer.17.attention.self.key.bias\n",
    "bert.encoder.layer.17.attention.self.value.weight\n",
    "bert.encoder.layer.17.attention.self.value.bias\n",
    "bert.encoder.layer.17.attention.output.dense.weight\n",
    "bert.encoder.layer.17.attention.output.dense.bias\n",
    "bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.17.intermediate.dense.weight\n",
    "bert.encoder.layer.17.intermediate.dense.bias\n",
    "bert.encoder.layer.17.output.dense.weight\n",
    "bert.encoder.layer.17.output.dense.bias\n",
    "bert.encoder.layer.17.output.LayerNorm.weight\n",
    "bert.encoder.layer.17.output.LayerNorm.bias\n",
    "bert.encoder.layer.18.attention.self.query.weight\n",
    "bert.encoder.layer.18.attention.self.query.bias\n",
    "bert.encoder.layer.18.attention.self.key.weight\n",
    "bert.encoder.layer.18.attention.self.key.bias\n",
    "bert.encoder.layer.18.attention.self.value.weight\n",
    "bert.encoder.layer.18.attention.self.value.bias\n",
    "bert.encoder.layer.18.attention.output.dense.weight\n",
    "bert.encoder.layer.18.attention.output.dense.bias\n",
    "bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.18.intermediate.dense.weight\n",
    "bert.encoder.layer.18.intermediate.dense.bias\n",
    "bert.encoder.layer.18.output.dense.weight\n",
    "bert.encoder.layer.18.output.dense.bias\n",
    "bert.encoder.layer.18.output.LayerNorm.weight\n",
    "bert.encoder.layer.18.output.LayerNorm.bias\n",
    "bert.encoder.layer.19.attention.self.query.weight\n",
    "bert.encoder.layer.19.attention.self.query.bias\n",
    "bert.encoder.layer.19.attention.self.key.weight\n",
    "bert.encoder.layer.19.attention.self.key.bias\n",
    "bert.encoder.layer.19.attention.self.value.weight\n",
    "bert.encoder.layer.19.attention.self.value.bias\n",
    "bert.encoder.layer.19.attention.output.dense.weight\n",
    "bert.encoder.layer.19.attention.output.dense.bias\n",
    "bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.19.intermediate.dense.weight\n",
    "bert.encoder.layer.19.intermediate.dense.bias\n",
    "bert.encoder.layer.19.output.dense.weight\n",
    "bert.encoder.layer.19.output.dense.bias\n",
    "bert.encoder.layer.19.output.LayerNorm.weight\n",
    "bert.encoder.layer.19.output.LayerNorm.bias\n",
    "bert.encoder.layer.20.attention.self.query.weight\n",
    "bert.encoder.layer.20.attention.self.query.bias\n",
    "bert.encoder.layer.20.attention.self.key.weight\n",
    "bert.encoder.layer.20.attention.self.key.bias\n",
    "bert.encoder.layer.20.attention.self.value.weight\n",
    "bert.encoder.layer.20.attention.self.value.bias\n",
    "bert.encoder.layer.20.attention.output.dense.weight\n",
    "bert.encoder.layer.20.attention.output.dense.bias\n",
    "bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.20.intermediate.dense.weight\n",
    "bert.encoder.layer.20.intermediate.dense.bias\n",
    "bert.encoder.layer.20.output.dense.weight\n",
    "bert.encoder.layer.20.output.dense.bias\n",
    "bert.encoder.layer.20.output.LayerNorm.weight\n",
    "bert.encoder.layer.20.output.LayerNorm.bias\n",
    "bert.encoder.layer.21.attention.self.query.weight\n",
    "bert.encoder.layer.21.attention.self.query.bias\n",
    "bert.encoder.layer.21.attention.self.key.weight\n",
    "bert.encoder.layer.21.attention.self.key.bias\n",
    "bert.encoder.layer.21.attention.self.value.weight\n",
    "bert.encoder.layer.21.attention.self.value.bias\n",
    "bert.encoder.layer.21.attention.output.dense.weight\n",
    "bert.encoder.layer.21.attention.output.dense.bias\n",
    "bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.21.intermediate.dense.weight\n",
    "bert.encoder.layer.21.intermediate.dense.bias\n",
    "bert.encoder.layer.21.output.dense.weight\n",
    "bert.encoder.layer.21.output.dense.bias\n",
    "bert.encoder.layer.21.output.LayerNorm.weight\n",
    "bert.encoder.layer.21.output.LayerNorm.bias\n",
    "bert.encoder.layer.22.attention.self.query.weight\n",
    "bert.encoder.layer.22.attention.self.query.bias\n",
    "bert.encoder.layer.22.attention.self.key.weight\n",
    "bert.encoder.layer.22.attention.self.key.bias\n",
    "bert.encoder.layer.22.attention.self.value.weight\n",
    "bert.encoder.layer.22.attention.self.value.bias\n",
    "bert.encoder.layer.22.attention.output.dense.weight\n",
    "bert.encoder.layer.22.attention.output.dense.bias\n",
    "bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.22.intermediate.dense.weight\n",
    "bert.encoder.layer.22.intermediate.dense.bias\n",
    "bert.encoder.layer.22.output.dense.weight\n",
    "bert.encoder.layer.22.output.dense.bias\n",
    "bert.encoder.layer.22.output.LayerNorm.weight\n",
    "bert.encoder.layer.22.output.LayerNorm.bias\n",
    "bert.encoder.layer.23.attention.self.query.weight\n",
    "bert.encoder.layer.23.attention.self.query.bias\n",
    "bert.encoder.layer.23.attention.self.key.weight\n",
    "bert.encoder.layer.23.attention.self.key.bias\n",
    "bert.encoder.layer.23.attention.self.value.weight\n",
    "bert.encoder.layer.23.attention.self.value.bias\n",
    "bert.encoder.layer.23.attention.output.dense.weight\n",
    "bert.encoder.layer.23.attention.output.dense.bias\n",
    "bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
    "bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
    "bert.encoder.layer.23.intermediate.dense.weight\n",
    "bert.encoder.layer.23.intermediate.dense.bias\n",
    "bert.encoder.layer.23.output.dense.weight\n",
    "bert.encoder.layer.23.output.dense.bias\n",
    "bert.encoder.layer.23.output.LayerNorm.weight\n",
    "bert.encoder.layer.23.output.LayerNorm.bias\n",
    "qa_outputs.weight\n",
    "qa_outputs.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767a0c3-1350-480e-ad51-db361ffaa6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'torch.nn.parameter.Parameter'>\n",
      "bert.encoder.layer.23.output.LayerNorm.weight Parameter containing:\n",
      "tensor([0.8091, 0.8709, 0.7699,  ..., 0.7874, 0.8123, 0.7840], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor(0.8091, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-e84825b73765>\", line 35, in <module>\n",
      "    param.data[0] = torch.rand(1024)\n",
      "RuntimeError: expand(torch.FloatTensor{[1024]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-e84825b73765>\", line 35, in <module>\n",
      "    param.data[0] = torch.rand(1024)\n",
      "RuntimeError: expand(torch.FloatTensor{[1024]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-e84825b73765>\", line 35, in <module>\n",
      "    param.data[0] = torch.rand(1024)\n",
      "RuntimeError: expand(torch.FloatTensor{[1024]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# replace <PATd:/spofrte/modeH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "# load model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "for name,param in model.named_parameters():\n",
    "    if name == 'qa_outputs.weight':\n",
    "        print(type(name), type(param))\n",
    "        print(name, param)\n",
    "        print(param.data[0])\n",
    "        param.data[0] = torch.rand(1024)\n",
    "        print(param.data[0])\n",
    "    if name == 'bert.encoder.layer.23.output.LayerNorm.weight':\n",
    "        print(type(name), type(param))\n",
    "        print(name, param)\n",
    "        print(param.data[0])\n",
    "        param.data[0] = torch.rand(1024)\n",
    "        print(param.data[0])\n",
    "\n",
    "\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids, attention_mask=attention_mask, )\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values\n",
    "\n",
    "fig = plt.figure()  \n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "ref_token_id = tokenizer.pad_token_id  # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id  # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id  # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)  # * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=token_type_ids,\n",
    "                                                 position_ids=position_ids)\n",
    "\n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "def predict_qt(question, text):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id,\n",
    "                                                                cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = '13'\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, \\\n",
    "                                       token_type_ids=token_type_ids, \\\n",
    "                                       position_ids=position_ids, \\\n",
    "                                       attention_mask=attention_mask)\n",
    "\n",
    "    print('Question: ', question)\n",
    "    print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1]))\n",
    "    return input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens,\n",
    "\n",
    "\n",
    "def explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores,\n",
    "            ground_truth, all_tokens, ):\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, model.bert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "                                                    baselines=ref_input_ids,\n",
    "                                                    additional_forward_args=(\n",
    "                                                        token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                    internal_batch_size=4,\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids,\n",
    "                                                additional_forward_args=(\n",
    "                                                    token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                internal_batch_size=4,\n",
    "                                                return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_start_sum,\n",
    "        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "        torch.argmax(start_scores),\n",
    "        torch.argmax(start_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_start_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_start)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_end_sum,\n",
    "        torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "        torch.argmax(end_scores),\n",
    "        torch.argmax(end_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_end_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_end)\n",
    "    #print(all_tokens)\n",
    "    print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "    viz.visualize_text([start_position_vis])\n",
    "\n",
    "    print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "\n",
    "    print(\"attributions_start_sum:   \", len(attributions_start_sum))\n",
    "    #print(\"all tokens:    \", len(all_tokens))\n",
    "\n",
    "    return all_tokens, attributions_start_sum\n",
    "\n",
    "\n",
    "def get_posneg(all_tokens, attributions_start_sum):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "    for i, j in enumerate(attributions_start_sum):\n",
    "        if j > 0:\n",
    "            positive.append(i)\n",
    "            # print('positive:',j)\n",
    "        ##print(all_tokens[i])\n",
    "        elif j < 0:\n",
    "            negative.append(i)\n",
    "            # print('negative:',j)\n",
    "            # print(all_tokens[i])\n",
    "        elif j == 0:\n",
    "            neutral.append(i)\n",
    "\n",
    "    s_pos = ''\n",
    "    s_neg = ''\n",
    "\n",
    "    # print(len(attributions_start_sum))\n",
    "    # print(len(positive))\n",
    "    # print(len(negative))\n",
    "\n",
    "    for i in positive:\n",
    "        s_pos += all_tokens[i] + ' '\n",
    "    #print(\"positive :\", s_pos)\n",
    "    for i in negative:\n",
    "        s_neg += all_tokens[i] + ' '\n",
    "    #print(\"negative :\", s_neg)\n",
    "    return positive, negative, neutral\n",
    "\n",
    "\n",
    "def separate_sentence(all_tokens):\n",
    "    sentence = {}\n",
    "    temp = []\n",
    "    num = 0\n",
    "    for i in range(len(all_tokens)):\n",
    "        if all_tokens[i] == \",\" or all_tokens[i] == \".\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[CLS]\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[SEP]\":\n",
    "            sentence[num] = temp\n",
    "            num = num + 1\n",
    "            temp = [all_tokens[i]]\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        else:\n",
    "            temp.append(all_tokens[i])\n",
    "    return sentence\n",
    "def get_sence_score(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value=[]\n",
    "    delete_sentence = []\n",
    "    for k,v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores={}\n",
    "\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]]=attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight +=  scores[word]\n",
    "        delete_sentence.append(sum_weight)\n",
    "        #print(sum_weight)\n",
    "    return delete_sentence\n",
    "\n",
    "def get_delete(sentence):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = {}\n",
    "    for k, v in sentence.items():\n",
    "        # print(k,':',v)\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    #print(sentence_value)\n",
    "    scores = {}\n",
    "    # print(attributions_start_sum[0].item())\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            weight = 0\n",
    "\n",
    "            sum_weight += scores[word]\n",
    "            delete_sentence[i] = sum_weight\n",
    "    return delete_sentence\n",
    "\n",
    "\n",
    "def delete_sentence(sentence, li_delete_sentence):\n",
    "    for i, j in sentence.items():\n",
    "        if i in li_delete_sentence:\n",
    "            sentence[i] = []\n",
    "        else:\n",
    "            pass\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def rebuild_sentence(ori_sentence):\n",
    "    rebuild_str = \"\"\n",
    "    for i, j in ori_sentence.items():\n",
    "        for word in j:\n",
    "            rebuild_str += word\n",
    "            rebuild_str += \" \"\n",
    "    return rebuild_str\n",
    "\n",
    "\n",
    "def pred_explain(question, text):\n",
    "    input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens, = predict_qt(\n",
    "        text, question)\n",
    "\n",
    "    all_tokens, attributions_start_sum = explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask,\n",
    "                                                 start_scores, end_scores, ground_truth, all_tokens, )\n",
    "\n",
    "    end_score = float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "    start_score = float(torch.max(torch.softmax(start_scores[0], dim=0)))\n",
    "    return all_tokens, attributions_start_sum, end_score, start_score, [torch.argmax(start_scores), torch.argmax(end_scores)+1], start_scores, end_scores\n",
    "def max_min(x, y, z):\n",
    "    max = min = x\n",
    "    i = 1\n",
    "    if y > max:\n",
    "        max = y\n",
    "        i = 2\n",
    "    else:\n",
    "        min = y\n",
    "    if z > max:\n",
    "        max = z\n",
    "        i =3\n",
    "    else:\n",
    "        min = z\n",
    "    return (i)\n",
    "def cycle_prediction(cycle_num, question, text):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)\n",
    "    first_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    first_answer = re.sub(r' ##', '', first_answer)\n",
    "    print(\"my answer is \", first_answer)\n",
    "    print(start_acc, end_acc)\n",
    "    second_answer = ''\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    a = 0\n",
    "    pos_contri = 0\n",
    "    neg_contri = 0\n",
    "    average_neg = []\n",
    "    average_pos = []\n",
    "    for i, j in enumerate(attributions_start_sum):\n",
    "        if j <0 : \n",
    "            neg_contri+= j\n",
    "        elif j >0:\n",
    "            pos_contri += j\n",
    "    print(\"positive contribution:\", pos_contri)\n",
    "    average_pos.append(pos_contri)\n",
    "    print(\"negative contribution:\", neg_contri)\n",
    "    average_neg.append(neg_contri)\n",
    "\n",
    "    acc_s = []\n",
    "    acc_e = []\n",
    "    sun = []\n",
    "    ans = []\n",
    "    ans.append(first_answer)\n",
    "    #print(start_acc, end_acc)\n",
    "    acc_s.append(start_acc)\n",
    "    acc_e.append(end_acc)\n",
    "\n",
    "    for loop in range(cycle_num):\n",
    "        sentence = separate_sentence(all_tokens)\n",
    "        sentence_score  = get_sence_score(sentence, attributions_start_sum)\n",
    "        min_sensocer = 999\n",
    "        min_index = 999\n",
    "        for i in range(len(sentence_score)):\n",
    "            if sentence_score[i] < min_sensocer and sentence_score[i] != 0:\n",
    "                min_sensocer = sentence_score[i]\n",
    "                min_index = i\n",
    "        #print(\"should delete\", min_index, min_sensocer)\n",
    "        sentence[min_index] = ''\n",
    "        sentence[1] = ''\n",
    "        retext = \"\"\n",
    "        for i, j in sentence.items():\n",
    "            for words in j:\n",
    "                retext = retext + words + \" \"\n",
    "        li_sep = []\n",
    "        for m in re.finditer(r\"SEP\", retext):\n",
    "            li_sep.append(m.start())\n",
    "            li_sep.append(m.end())\n",
    "        retext = retext[li_sep[1]+1: li_sep[2] -1]\n",
    "        retext = re.sub(r' ##', '', retext)\n",
    "\n",
    "\n",
    "\n",
    "        all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores= pred_explain(retext, question)\n",
    "        reanswer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        #print(start_acc, end_acc)\n",
    "        second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        #print(\"my answer is \", second_answer)\n",
    "        ans.append(second_answer)\n",
    "        #print(start_acc, end_acc)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "        pos_contri = 0\n",
    "        neg_contri = 0\n",
    "        for i, j in enumerate(attributions_start_sum):\n",
    "            if j <0:\n",
    "                neg_contri+= j\n",
    "            elif j >0:\n",
    "                pos_contri += j\n",
    "        print(\"positive contribution:\", pos_contri)\n",
    "        average_pos.append(pos_contri)\n",
    "        print(\"negative contribution:\", neg_contri)\n",
    "        average_neg.append(neg_contri)\n",
    "\n",
    "\n",
    "        #print(acc_s, acc_e)\n",
    "        #print(acc_s, acc_e)\n",
    "    plt.plot(range(len(acc_s)), acc_s, label = 'start score')\n",
    "    plt.plot(range(len(acc_s)), acc_e, label = 'end score')\n",
    "    sun = []\n",
    "    for i in range(len(acc_s)):\n",
    "        sun.append((acc_s[i] + acc_e[i])/2)\n",
    "    print(sun)\n",
    "    plt.plot(range(len(acc_s)), sun, label = 'average')\n",
    "    plt.xlabel('Number of predictions')\n",
    "    plt.ylabel('Possibility')    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    \"\"\"\"获取最好的曲线并输出\"\"\"\n",
    "    max_start = 0\n",
    "    max_end = 0\n",
    "    max_ave = 0\n",
    "    for i in acc_s:\n",
    "        if i > max_start:\n",
    "            max_start = i\n",
    "    for j in acc_e:\n",
    "        if j > max_end:\n",
    "            max_end = i\n",
    "\n",
    "    for x in sun:\n",
    "        if x > max_ave:\n",
    "            max_ave = x\n",
    "\n",
    "    print(max_start ,max_end ,max_ave )\n",
    "\n",
    "\n",
    "    max_list = max_min(max_start, max_end, max_ave)\n",
    "    if max_list == 1:\n",
    "        plt.plot(range(len(acc_s)), acc_s, label = 'Possibility')\n",
    "        print(acc_s)\n",
    "    if max_list == 2:\n",
    "        plt.plot(range(len(acc_e)), acc_e, label = 'Possibility')\n",
    "        print(acc_e)\n",
    "    if max_list == 3:\n",
    "        plt.plot(range(len(sun)), sun, label = 'Possibility')\n",
    "        print(sun)\n",
    "\n",
    "    plt.xlabel('Number of predictions')\n",
    "    plt.ylabel('Possibility')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \"\"\"贡献的数值分别是多少\"\"\"\n",
    "    plt.plot(range(len(average_pos)), average_pos, label = 'pos score')\n",
    "    plt.plot(range(len(average_neg)), average_neg, label = 'neg score')\n",
    "    plt.xlabel('Number of predictions')\n",
    "    plt.ylabel('average contribution of pos/neg')    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    for i in range(len(ans)):\n",
    "        print(ans[i], \"pos/neg : \", -(average_pos[i]/average_neg[i]))\n",
    "    average_contribution = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f36f0-c8fe-4de3-944f-7740476c31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-845683585c58>\", line 4, in <module>\n",
      "    all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)\n",
      "NameError: name 'pred_explain' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 124\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-845683585c58>\", line 4, in <module>\n",
      "    all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)\n",
      "NameError: name 'pred_explain' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-845683585c58>\", line 4, in <module>\n",
      "    all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)\n",
      "NameError: name 'pred_explain' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "text = \"A self-described 'modern-day feminist', Beyoncé creates songs that are often characterized by themes of love, relationships, and monogamy, as well as female sexuality and empowerment. On stage, her dynamic, highly choreographed performances have led to critics hailing her as one of the best entertainers in contemporary popular music. Throughout a career spanning 19 years, she has sold over 118 million records as a solo artist, and a further 60 million with Destiny's Child, making her one of the best-selling music artists of all time. She has won 20 Grammy Awards and is the most nominated woman in the award's history. The Recording Industry Association of America recognized her as the Top Certified Artist in America during the 2000s decade. In 2009, Billboard named her the Top Radio Songs Artist of the Decade, the Top Female Artist of the 2000s and their Artist of the Millennium in 2011. Time listed her among the 100 most influential people in the world in 2013 and 2014. Forbes magazine also listed her as the most powerful female musician of 2015.\"\n",
    "question = \"What magazine named Beyoncé as the most powerful female musician for 2015?\"\n",
    "\n",
    "all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79055c5a-323b-4e5c-af06-c53421790eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ee5dd427ff63>\", line 2, in <module>\n",
      "    for i, j in enumerate(attributions_start_sum):\n",
      "NameError: name 'attributions_start_sum' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 125\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ee5dd427ff63>\", line 2, in <module>\n",
      "    for i, j in enumerate(attributions_start_sum):\n",
      "NameError: name 'attributions_start_sum' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ee5dd427ff63>\", line 2, in <module>\n",
      "    for i, j in enumerate(attributions_start_sum):\n",
      "NameError: name 'attributions_start_sum' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\software\\Anoconda\\envs\\xai\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "attr_nomal = []\n",
    "for i, j in enumerate(attributions_start_sum):\n",
    "    attr_nomal.append(j)\n",
    "plt.plot(range(len(attr_nomal)), attr_nomal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cebdd-1df5-41cb-8d49-f6925f1fbb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
