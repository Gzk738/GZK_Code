{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f566bd91-174e-4d18-87c7-731fba5f6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.34193170070648193 0.4017501771450043\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "sep_model = torch.load(\"sep_DistilBertForQuestionAnswering.pth\")\n",
    "offical_model =  torch.load(\"DistilBertForQuestionAnswering.pth\")\n",
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "\n",
    "\n",
    "def predict(model, inputs):\n",
    "    output = model(inputs)\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def predict_qt(model, text, question):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = '13'\n",
    "\n",
    "\n",
    "    start_scores, end_scores = predict(model, input_ids)\n",
    "\n",
    "\n",
    "    return (' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])), float(torch.max(torch.softmax(start_scores[0], dim=0))), float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "\n",
    "question = \"\"\"When did Beyonce start becoming popular?\"\"\"\n",
    "text = \"\"\"Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\"\"\"\n",
    "answer, start_scores, end_scores= predict_qt(offical_model, question, text)\n",
    "print(answer,start_scores, end_scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac437651-d35f-40d4-914e-d7435e6807e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c02b239-24d9-4760-b4c4-35a5011dfcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singing and dancing 0.9882990121841431 0.8989322185516357\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"What areas did Beyonce compete in when she was growing up?\"\"\"\n",
    "\n",
    "answer, start_scores, end_scores = predict_qt(offical_model, question, text)\n",
    "print(answer,start_scores, end_scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c7dceb6-3514-4126-8878-c62b204dab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress.\n",
      "========> september 4 , 1981 0.732269287109375 0.48283758759498596\n",
      "************************************************************************\n",
      "Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child.\n",
      "========> late 1990s 0.4097570478916168 0.9200773239135742\n",
      "************************************************************************\n",
      "Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time.\n",
      "========> her father , mathew knowles , the group became one of the world ' s best - selling girl groups of all time 0.4172043204307556 0.5592108368873596\n",
      "************************************************************************\n",
      "Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "========> 2003 0.7688779234886169 0.6429992318153381\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk as tk\n",
    "import re\n",
    "tokens = tk.sent_tokenize(text)\n",
    "for token in tokens:\n",
    "    print(token)\n",
    "\n",
    "    answer, start_scores, end_scores = predict_qt(sep_model, question, token)\n",
    "    print(\"========>\", answer,start_scores, end_scores)\n",
    "    print(\"*\"*72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fdc29c-f042-456c-983b-835f40ee1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_squad(path):\n",
    "    path = Path(path)\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "\n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_squad(r'D:\\software\\github\\GZK_Code\\XAI\\2022.03.03\\squad\\train-v2.0.json')\n",
    "val_contexts, val_questions, val_answers = read_squad(r'D:\\software\\github\\GZK_Code\\XAI\\2022.03.03\\squad\\dev-v2.0.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6e62046-8d33-4226-9297-990ec2af5b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86821"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860c99d0-2e5e-409a-9611-86be4a9005ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sep_train_contexts = []\n",
    "sep_train_questions = []\n",
    "sep_train_answers = []\n",
    "import nltk as tk\n",
    "import re\n",
    "temp = 0\n",
    "null_answer = {'text': '[NULL]', 'answer_start': 0}\n",
    "for i in range(len(train_contexts)):\n",
    "    tokens = tk.sent_tokenize(train_contexts[i])\n",
    "    for token in tokens:\n",
    "        if train_answers[i]['text'] in token:\n",
    "            try:\n",
    "                answer_start = re.search(train_answers[i]['text'], token)\n",
    "                answer = {'text': train_answers[i]['text'], 'answer_start':  answer_start.span()[0]}\n",
    "                sep_train_contexts.append(token)\n",
    "\n",
    "            \n",
    "                sep_train_answers.append(answer)\n",
    "                sep_train_questions.append(train_questions[i])\n",
    "            except:\n",
    "                temp = temp + 1\n",
    "print(temp)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450cf58a-6846-48d9-9741-58579aa7c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Beyoncé has won 20 Grammy Awards, both as a solo artist and member of Destiny's Child, making her the second most honored female artist by the Grammys, behind Alison Krauss and the most nominated woman in Grammy Award history with 52 nominations.\", '\"Single Ladies (Put a Ring on It)\" won Song of the Year in 2010 while \"Say My Name\" and \"Crazy in Love\" had previously won Best R&B Song.', \"Dangerously in Love, B'Day and I Am... Sasha Fierce have all won Best Contemporary R&B Album.\", 'Beyoncé set the record for the most Grammy awards won by a female artist in one night in 2010 when she won six awards, breaking the tie she previously held with Alicia Keys, Norah Jones, Alison Krauss, and Amy Winehouse, with Adele equaling this in 2012.', 'Following her role in Dreamgirls she was nominated for Best Original Song for \"Listen\" and Best Actress at the Golden Globe Awards, and Outstanding Actress in a Motion Picture at the NAACP Image Awards.', 'Beyoncé won two awards at the Broadcast Film Critics Association Awards 2006; Best Song for \"Listen\" and Best Original Soundtrack for Dreamgirls: Music from the Motion Picture.']\n",
      "\"Single Ladies (Put a Ring on It)\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'span'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_answers[\u001b[38;5;241m636\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[0;32m      6\u001b[0m     answer_start \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(train_answers[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], token)\n\u001b[1;32m----> 7\u001b[0m     answer \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: train_answers[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_start\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[43manswer_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspan\u001b[49m()[\u001b[38;5;241m0\u001b[39m]}\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, train_answers[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'span'"
     ]
    }
   ],
   "source": [
    "tokens = tk.sent_tokenize(train_contexts[636])\n",
    "print(tokens)\n",
    "print(train_answers[636]['text'])\n",
    "for token in tokens:\n",
    "    if train_answers[636]['text'] in token:\n",
    "        answer_start = re.search(train_answers[i]['text'], token)\n",
    "        answer = {'text': train_answers[i]['text'], 'answer_start':  answer_start.span()[0]}\n",
    "        print('text', train_answers[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd43a4-7df3-4e2c-a7e3-e036873e0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sep_train_contexts)):\n",
    "    print(\"CONTEXT ==>\", sep_train_contexts[i])\n",
    "    print(\"QUESTION ==>\", sep_train_questions[i])\n",
    "    print(\"ANSWERS ==>\", sep_train_answers[i])\n",
    "    print(\"*\"*74)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
