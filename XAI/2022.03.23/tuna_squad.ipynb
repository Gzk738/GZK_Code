{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dc908cf7-e21a-40de-9045-d661e7bdc6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\GZK\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fba5f1bced418ab40456a910bd05ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0ae3a52d115f18f2\n",
      "Reusing dataset csv (C:\\Users\\GZK\\.cache\\huggingface\\datasets\\csv\\default-0ae3a52d115f18f2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd4168dbba64fb480caba1398a51a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Loading cached processed dataset at C:\\Users\\GZK\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-1b0a3f8f58942c64.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f06856f1cb446283fe8dc5eec5968e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\GZK\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-55e3b8927d96553d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\GZK\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-c50c38f20d2316ae.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad\")\n",
    "sep_squad = load_dataset('csv', data_files={'train': './sep_squad_train.csv', 'validation': './sep_squad_validation.csv'})\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "\n",
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)\n",
    "sep_tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "data_collator = default_data_collator\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07412bb-b0c6-401f-9678-e51cd152b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')) + 'full_squadh'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "torch.save(model, './models/' + model_name)\n",
    "for epoch in range(10):\n",
    "    model = torch.load(\"./models/\" + model_name)\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    answers = {}\n",
    "    for org_id in org:\n",
    "        if org_id in ids:\n",
    "            text = texts[ids.index(org_id)]\n",
    "            if len(text) >=512:\n",
    "                text = text[:512]\n",
    "            question = ques[ids.index(org_id)]\n",
    "            answer, start_scores, end_scores= predict_qt(model, text, question)\n",
    "            answers[org_id] = answer\n",
    "        elif org_id not in ids:\n",
    "            print(org_id, \"didn't found\")\n",
    "            answers[org_id] = ''\n",
    "    json_str = json.dumps(answers)\n",
    "    with open('./answers/'+model_name+'my_answers.txt', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "    model_name = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')) + 'full_squad.pth'\n",
    "    torch.save(model, './models/' + model_name )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d56817-ba19-4b18-b41f-5b3a3ae058a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(10):\n",
    "    model = torch.load(\"./models/\" + model_name)\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=sep_tokenized_squad[\"train\"],\n",
    "    eval_dataset=sep_tokenized_squad[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    answers = {}\n",
    "    for org_id in org:\n",
    "        if org_id in ids:\n",
    "            text = texts[ids.index(org_id)]\n",
    "            if len(text) >=512:\n",
    "                text = text[:512]\n",
    "            question = ques[ids.index(org_id)]\n",
    "            answer, start_scores, end_scores= predict_qt(model, text, question)\n",
    "            answers[org_id] = answer\n",
    "        elif org_id not in ids:\n",
    "            print(org_id, \"didn't found\")\n",
    "            answers[org_id] = ''\n",
    "    json_str = json.dumps(answers)\n",
    "    with open('./answers/'+model_name+'my_answers.txt', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "    model_name = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')) + 'sep_squad.pth'\n",
    "    torch.save(model, './models/' + model_name )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2644d1-559b-498b-a25a-fce0f73323cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=sep_tokenized_squad[\"train\"],\n",
    "    eval_dataset=sep_tokenized_squad[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2cda6-1054-418f-8758-c892ee1ceaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')) + 'full_squadh'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "torch.save(model, './models/' + model_name)\n",
    "for epoch in range(10):\n",
    "    model = torch.load(\"./models/\" + model_name)\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    model_name = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')) + 'full_squad.pth'\n",
    "    torch.save(model, './models/' + model_name )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb84ee1c-4a21-440a-ad36-ffa23dae3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def predict(model, inputs):\n",
    "    output = model(inputs)\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def predict_qt(model, text, question):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    start_scores, end_scores = predict(model, input_ids)\n",
    "\n",
    "\n",
    "    return (' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])), float(torch.max(torch.softmax(start_scores[0], dim=0))), float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32942d63-27cf-41ef-b946-ed51b05c4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "ques = []\n",
    "texts = []\n",
    "for i in squad[\"validation\"]:\n",
    "    ids.append(i['id'])\n",
    "    ques.append(i['question'])\n",
    "    texts.append(i['context'])\n",
    "import json\n",
    "with open(\"worksheets.codalab.org.txt\", \"r+\")as f:\n",
    "    org = json.load(f)\n",
    "print(\"org : \", len(org))\n",
    "print(\"ids : \", len(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120d6ea-720c-4b15-911a-a6fbdb30db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}\n",
    "for org_id in org:\n",
    "    if org_id in ids:\n",
    "        text = texts[ids.index(org_id)]\n",
    "        if len(text) >=512:\n",
    "            text = text[:512]\n",
    "        question = ques[ids.index(org_id)]\n",
    "        answer, start_scores, end_scores= predict_qt(model, text, question)\n",
    "        answers[org_id] = answer\n",
    "    elif org_id not in ids:\n",
    "        print(org_id, \"didn't found\")\n",
    "        answers[org_id] = ''\n",
    "json_str = json.dumps(answers)\n",
    "with open('my_answers.txt', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93ce09ec-e8cb-44fe-b40d-e6cd604bdc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_answers.txt\", \"w\", encoding='utf-8')as f:\n",
    "    f.write(str(answers), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7c45a53-c12b-4759-b00c-4501adee2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(answers)\n",
    "with open('my_answers.txt', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "210ed34c-91c1-43f3-824e-0de0f174ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\GZK/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "import torch\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc7c7aee-357d-47ad-9794-3104604a5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertForQuestionAnswering\n",
    "# model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "# model.to(device)\n",
    "model = torch.load('./models/epoch72022-03-20-23-56-16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "147bd5cc-1c55-46e4-983a-af19ae378fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-23-20-45-43\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "time = str(datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "print(time)\n",
    "answers = {}\n",
    "for org_id in org:\n",
    "    if org_id in ids:\n",
    "        text = texts[ids.index(org_id)]\n",
    "        if len(text) >=512:\n",
    "            text = text[:512]\n",
    "        question = ques[ids.index(org_id)]\n",
    "        answer, start_scores, end_scores= predict_qt(model, text, question)\n",
    "        answers[org_id] = answer\n",
    "    elif org_id not in ids:\n",
    "        #print(org_id, \"didn't found\")\n",
    "        answers[org_id] = ''\n",
    "json_str = json.dumps(answers)\n",
    "with open(time + 'my_answers.txt', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3d52e546-bf09-418f-99de-7df9ef29e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contexts = []\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "train_titles = []\n",
    "train_ids = []\n",
    "\n",
    "validation_contexts = []\n",
    "validation_questions = []\n",
    "validation_answers = []\n",
    "validation_titles = []\n",
    "validation_ids = []\n",
    "for i in squad['train']:\n",
    "    train_contexts.append(i['context'])\n",
    "    train_questions.append(i['question'])\n",
    "    train_answers.append(i['answers'])\n",
    "    train_titles.append(i['title'])\n",
    "    train_ids.append(i['id'])\n",
    "    \n",
    "    \n",
    "for i in squad['validation']:\n",
    "    validation_contexts.append(i['context'])\n",
    "    validation_questions.append(i['question'])\n",
    "    validation_answers.append(i['answers'])\n",
    "    validation_titles.append(i['title'])\n",
    "    validation_ids.append(i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c32a1ecd-ef1a-4e3b-b47f-a8512f448bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-201d4e794bdec093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\GZK\\.cache\\huggingface\\datasets\\csv\\default-201d4e794bdec093\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbed0889d5e4f099ad4f3b24c108684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9182cc25a9c043dd8c66425fa98494cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\GZK\\.cache\\huggingface\\datasets\\csv\\default-201d4e794bdec093\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d2214e0da04b5e9a4d22b2b8a9af2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files={'train': './train.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aae27667-6333-440b-b3aa-fc60f375477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_index :  1770\n",
      "error_index :  213\n"
     ]
    }
   ],
   "source": [
    "import nltk as tk\n",
    "import re\n",
    "\n",
    "sep_train_contexts = []\n",
    "sep_train_questions = []\n",
    "sep_train_answers = []\n",
    "sep_train_ids = []\n",
    "sep_train_titles = []\n",
    "\n",
    "sep_validation_contexts = []\n",
    "sep_validation_questions = []\n",
    "sep_validation_answers = []\n",
    "sep_validation_ids = []\n",
    "sep_validation_titles = []\n",
    "\n",
    "error_index = []\n",
    "null_answer = {'text': '[NULL]', 'answer_start': 0}\n",
    "for i in range(len(train_contexts)):\n",
    "    tokens = tk.sent_tokenize(train_contexts[i])\n",
    "    for token in tokens:\n",
    "        if train_answers[i]['text'][0] in token:\n",
    "            try:\n",
    "                answer_start = re.search(train_answers[i]['text'][0], token)\n",
    "                answer = {'text': train_answers[i]['text'], 'answer_start': answer_start.span()[0]}\n",
    "                sep_train_contexts.append(token)\n",
    "\n",
    "                sep_train_answers.append(answer)\n",
    "                sep_train_questions.append(train_questions[i])\n",
    "                sep_train_ids.append(train_ids[i])\n",
    "                sep_train_titles.append(train_titles[i])\n",
    "            except:\n",
    "                error_index.append(i)\n",
    "\n",
    "                # print(i)\n",
    "        # else:\n",
    "        #     sep_train_contexts.append('[NULL]' + token)\n",
    "        #     sep_train_answers.append(null_answer)\n",
    "        #     sep_train_questions.append(train_questions[i])\n",
    "print(\"error_index : \", len(error_index))\n",
    "\n",
    "error_index = []\n",
    "null_answer = {'text': '[NULL]', 'answer_start': 0}\n",
    "for i in range(len(validation_contexts)):\n",
    "    tokens = tk.sent_tokenize(validation_contexts[i])\n",
    "    for token in tokens:\n",
    "        if validation_answers[i]['text'][0] in token:\n",
    "            try:\n",
    "                answer_start = re.search(validation_answers[i]['text'][0], token)\n",
    "                answer = {'text': validation_answers[i]['text'], 'answer_start': answer_start.span()[0]}\n",
    "                sep_validation_contexts.append(token)\n",
    "\n",
    "                sep_validation_answers.append(answer)\n",
    "                sep_validation_questions.append(validation_questions[i])\n",
    "                sep_validation_ids.append(validation_ids[i])\n",
    "                sep_validation_titles.append(validation_titles[i])\n",
    "            except:\n",
    "                error_index.append(i)\n",
    "\n",
    "                # print(i)\n",
    "        # else:\n",
    "        #     sep_train_contexts.append('[NULL]' + token)\n",
    "        #     sep_train_answers.append(null_answer)\n",
    "        #     sep_train_questions.append(train_questions[i])\n",
    "print(\"error_index : \", len(error_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28216d78-d5a0-4ce8-ad9c-0207cc0410dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sep_train_contexts), len(sep_train_questions), lsep_train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "52060622-91a2-4887-b977-2b9463818f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#字典中的key值即为csv中列名\n",
    "dataframe = pd.DataFrame({'id':train_ids,'title':train_titles, 'context':train_contexts, 'question':train_questions, 'answers':train_answers})\n",
    "\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "dataframe.to_csv(\"full_squad_train.csv\",index=False,sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6a13740b-d5b1-4f75-8076-9c414dc9a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dataframe = pd.DataFrame({'id':sep_train_ids,'title':sep_train_titles, 'context':sep_train_contexts, 'question':sep_train_questions, 'answers':sep_train_answers})\n",
    "\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "sep_dataframe.to_csv(\"sep_squad_train.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "540b5ec6-6838-4611-8953-63e6bce8d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dataframe = pd.DataFrame({'id':sep_validation_ids,\n",
    "                              'title':sep_validation_titles, \n",
    "                              'context':sep_validation_contexts, \n",
    "                              'question':sep_validation_questions, \n",
    "                              'answers':sep_validation_answers})\n",
    "\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "sep_dataframe.to_csv(\"sep_squad_validation.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2f92d0f4-060b-4fa2-88a4-5b50792a0a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0ae3a52d115f18f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\GZK\\.cache\\huggingface\\datasets\\csv\\default-0ae3a52d115f18f2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259e07ab73ec48d4a1e4d1b1821c418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f44765ec44455ab8d664427fb68596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\GZK\\.cache\\huggingface\\datasets\\csv\\default-0ae3a52d115f18f2\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe486985a414f66bf898134b0a72ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad = load_dataset('csv', data_files={'train': './sep_squad_train.csv', 'validation': './sep_squad_validation.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdee1521-7513-4280-b78d-89d2218df9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 59.159919028340084\n",
      "f1-------> 64.7655368790259\n",
      "total-------> 5928\n",
      "exact-------> 70.4457527333894\n",
      "f1-------> 70.4457527333894\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 64.81091552261434,\n",
      "  \"f1\": 67.60971132981278,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 59.159919028340084,\n",
      "  \"HasAns_f1\": 64.7655368790259,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 70.4457527333894,\n",
      "  \"NoAns_f1\": 70.4457527333894,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(os.popen(\"python evaluate-v2.0.py dev-v2.0.json worksheets.codalab.org.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b286d3e-526c-4033-8695-5481c315ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-22-21-00full_squadhmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-22-49-31full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-23-18-11full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-23-46-30full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-00-14-43full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-00-43-04full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-01-11-19full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-01-39-32full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-02-07-47full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-02-36-00full_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-03-04-14sep_squadhmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-03-32-38sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-00-51sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-29-03sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-57-17sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-05-25-29sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-05-53-41sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-06-21-53sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-06-50-06sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-07-18-18sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-07-46-31sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-08-14-46sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-08-42-58sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-09-11-10sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-09-39-20sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-10-07-33sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-10-35-46sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-11-03-59sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-11-32-11sep_squad.pthmy_answers.txt\n",
      "D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-12-00-24sep_squad.pthmy_answers.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_dir(text_list,dir_path):\n",
    "    dir_files = os.listdir(dir_path)  # 得到该文件夹下所有的文件\n",
    "    for file in dir_files:\n",
    "        file_path = os.path.join(dir_path, file)  # 路径拼接成绝对路径\n",
    "        if os.path.isfile(file_path):  # 如果是文件，就打印这个文件路径\n",
    "            if file_path.endswith(\".txt\"):\n",
    "                text_list.append(file_path)\n",
    "        if os.path.isdir(file_path):  # 如果目录，就递归子目录\n",
    "            list_dir(text_list,file_path)\n",
    "    return text_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_txt = []\n",
    "    thesaurus_path = r\"D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\"\n",
    "    text_list = list_dir(all_txt,thesaurus_path)\n",
    "    for text in text_list:\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a868916d-542d-4ebb-8b8c-b00703061cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-22-21-00full_squadhmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 33.28272604588394\n",
      "f1-------> 45.0971401088748\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.68912658974143,\n",
      "  \"f1\": 72.58787556349768,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 33.28272604588394,\n",
      "  \"HasAns_f1\": 45.0971401088748,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-22-49-31full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 34.64912280701754\n",
      "f1-------> 46.52270055274909\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 67.37134675313737,\n",
      "  \"f1\": 73.29963521238894,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 34.64912280701754,\n",
      "  \"HasAns_f1\": 46.52270055274909,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-23-18-11full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 33.87314439946019\n",
      "f1-------> 46.1960825502231\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.98391308009771,\n",
      "  \"f1\": 73.13656004023589,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 33.87314439946019,\n",
      "  \"HasAns_f1\": 46.1960825502231,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-23-23-46-30full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.96221322537112\n",
      "f1-------> 45.4229674826512\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.52909963783374,\n",
      "  \"f1\": 72.75055598729504,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.96221322537112,\n",
      "  \"HasAns_f1\": 45.4229674826512,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-00-14-43full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.388663967611336\n",
      "f1-------> 44.911741421466786\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.2427356186305,\n",
      "  \"f1\": 72.49530894857683,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.388663967611336,\n",
      "  \"HasAns_f1\": 44.911741421466786,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-00-43-04full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.20310391363023\n",
      "f1-------> 44.678778055574064\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.15008843594711,\n",
      "  \"f1\": 72.37899404644497,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.20310391363023,\n",
      "  \"HasAns_f1\": 44.678778055574064,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-01-11-19full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.865721997300945\n",
      "f1-------> 44.42483802357583\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.98163901288638,\n",
      "  \"f1\": 72.25220582866625,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.865721997300945,\n",
      "  \"HasAns_f1\": 44.42483802357583,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-01-39-32full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.865721997300945\n",
      "f1-------> 44.35488877380187\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.98163901288638,\n",
      "  \"f1\": 72.21728128115008,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.865721997300945,\n",
      "  \"HasAns_f1\": 44.35488877380187,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-02-07-47full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.663292847503374\n",
      "f1-------> 44.30855824080393\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.88056935904994,\n",
      "  \"f1\": 72.19414918314519,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.663292847503374,\n",
      "  \"HasAns_f1\": 44.30855824080393,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-02-36-00full_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.17408906882591\n",
      "f1-------> 44.075235133108684\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.6363176956119,\n",
      "  \"f1\": 72.07765466765497,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.17408906882591,\n",
      "  \"HasAns_f1\": 44.075235133108684,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-03-04-14sep_squadhmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 33.08029689608637\n",
      "f1-------> 44.92269498936726\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.588056935905,\n",
      "  \"f1\": 72.5007778907577,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 33.08029689608637,\n",
      "  \"HasAns_f1\": 44.92269498936726,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-03-32-38sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 34.49730094466936\n",
      "f1-------> 46.45173348243915\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 67.29554451276005,\n",
      "  \"f1\": 73.26420248327273,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 34.49730094466936,\n",
      "  \"HasAns_f1\": 46.45173348243915,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-00-51sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 33.906882591093115\n",
      "f1-------> 46.06757425476461\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 67.00075802240377,\n",
      "  \"f1\": 73.0723978928866,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 33.906882591093115,\n",
      "  \"HasAns_f1\": 46.06757425476461,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-29-03sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.89473684210526\n",
      "f1-------> 45.51014522109476\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.4954097532216,\n",
      "  \"f1\": 72.79408244509793,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.89473684210526,\n",
      "  \"HasAns_f1\": 45.51014522109476,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-04-57-17sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.11875843454791\n",
      "f1-------> 44.9571571735528\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.10797608018193,\n",
      "  \"f1\": 72.51798431102658,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.11875843454791,\n",
      "  \"HasAns_f1\": 44.9571571735528,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-05-25-29sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 32.253711201079625\n",
      "f1-------> 44.655656121774534\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.17535584940622,\n",
      "  \"f1\": 72.36744963276989,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 32.253711201079625,\n",
      "  \"HasAns_f1\": 44.655656121774534,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-05-53-41sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.815114709851553\n",
      "f1-------> 44.44587120022379\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.95637159942727,\n",
      "  \"f1\": 72.26270735912769,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.815114709851553,\n",
      "  \"HasAns_f1\": 44.44587120022379,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-06-21-53sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.916329284750336\n",
      "f1-------> 44.64346499523925\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 66.0069064263455,\n",
      "  \"f1\": 72.36136279725214,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.916329284750336,\n",
      "  \"HasAns_f1\": 44.64346499523925,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-06-50-06sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.427125506072876\n",
      "f1-------> 44.22250903492225\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.76265476290743,\n",
      "  \"f1\": 72.15118618369547,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.427125506072876,\n",
      "  \"HasAns_f1\": 44.22250903492225,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-07-18-18sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 30.988529014844804\n",
      "f1-------> 43.98693207542725\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.5436705129285,\n",
      "  \"f1\": 72.03356635586039,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 30.988529014844804,\n",
      "  \"HasAns_f1\": 43.98693207542725,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-07-46-31sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.05600539811066\n",
      "f1-------> 43.93710102806927\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.57736039754064,\n",
      "  \"f1\": 72.00868650672892,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.05600539811066,\n",
      "  \"HasAns_f1\": 43.93710102806927,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-08-14-46sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.140350877192983\n",
      "f1-------> 44.01351732965271\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.61947275330581,\n",
      "  \"f1\": 72.04683995032244,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.140350877192983,\n",
      "  \"HasAns_f1\": 44.01351732965271,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-08-42-58sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.37651821862348\n",
      "f1-------> 44.130092358806785\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.73738734944833,\n",
      "  \"f1\": 72.10504400766479,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.37651821862348,\n",
      "  \"HasAns_f1\": 44.130092358806785,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-09-11-10sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 30.97165991902834\n",
      "f1-------> 44.13817737151475\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.53524804177546,\n",
      "  \"f1\": 72.10908072587681,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 30.97165991902834,\n",
      "  \"HasAns_f1\": 44.13817737151475,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-09-39-20sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.477732793522268\n",
      "f1-------> 44.19775822957679\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.78792217636655,\n",
      "  \"f1\": 72.13882850037292,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.477732793522268,\n",
      "  \"HasAns_f1\": 44.19775822957679,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-10-07-33sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.781376518218625\n",
      "f1-------> 44.544936594349096\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.9395266571212,\n",
      "  \"f1\": 72.31216913427926,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.781376518218625,\n",
      "  \"HasAns_f1\": 44.544936594349096,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-10-35-46sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.68016194331984\n",
      "f1-------> 44.497941273095385\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.88899183020298,\n",
      "  \"f1\": 72.28870511807506,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.68016194331984,\n",
      "  \"HasAns_f1\": 44.497941273095385,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-11-03-59sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.747638326585694\n",
      "f1-------> 44.55666858821396\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.92268171481513,\n",
      "  \"f1\": 72.31802673215952,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.747638326585694,\n",
      "  \"HasAns_f1\": 44.55666858821396,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-11-32-11sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.68016194331984\n",
      "f1-------> 44.59878951322973\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.88899183020298,\n",
      "  \"f1\": 72.33905703987394,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.68016194331984,\n",
      "  \"HasAns_f1\": 44.59878951322973,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n",
      "python evaluate-v2.0.py dev-v2.0.json D:\\software\\github\\GZK_Code\\XAI\\2022.03.23\\answers\\2022-03-24-12-00-24sep_squad.pthmy_answers.txt\n",
      "OPTS.na_prob_thresh-------> <class 'float'> 1.0\n",
      "exact-------> 31.79824561403509\n",
      "f1-------> 44.6303948910765\n",
      "total-------> 5928\n",
      "exact-------> 100.0\n",
      "f1-------> 100.0\n",
      "total-------> 5945\n",
      "{\n",
      "  \"exact\": 65.94794912827423,\n",
      "  \"f1\": 72.35483710218979,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 31.79824561403509,\n",
      "  \"HasAns_f1\": 44.6303948910765,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 100.0,\n",
      "  \"NoAns_f1\": 100.0,\n",
      "  \"NoAns_total\": 5945\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in text_list:\n",
    "    cmd = \"python evaluate-v2.0.py dev-v2.0.json \" + text\n",
    "    print(cmd)\n",
    "    print(os.popen(cmd).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e815c13f-a5e2-4eca-8834-c71e8fe28f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'itchat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 导入模块\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitchat\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'itchat'"
     ]
    }
   ],
   "source": [
    "# 导入模块\n",
    "import itchat\n",
    "import datetime\n",
    "import time\n",
    "import itchat\n",
    "\n",
    "itchat.auto_login()\n",
    "\n",
    "itchat.send('hi', toUserName='小仙女')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb1d730-7636-4b29-9aa4-965fe1f72cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: itchat in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (1.2.32)\n",
      "Requirement already satisfied: requests in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from itchat) (2.27.1)\n",
      "Requirement already satisfied: pypng in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from itchat) (0.0.21)\n",
      "Requirement already satisfied: pyqrcode in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from itchat) (1.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from requests->itchat) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from requests->itchat) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from requests->itchat) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gzk\\anaconda3\\envs\\xai\\lib\\site-packages (from requests->itchat) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install itchat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
