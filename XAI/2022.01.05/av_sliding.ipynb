{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/zikun/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad45e1bd8ef64b1f987d66cd7776e2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my answer is  denver broncos\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 9]\n",
      "threshold :  3\n",
      "should delete :  [6, 9, 7]\n",
      "threshold :  4\n",
      "should delete :  [6, 9, 7, 5]\n",
      "0 个完成了\n",
      "my answer is  carolina panthers\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 9]\n",
      "threshold :  3\n",
      "should delete :  [6, 9, 7]\n",
      "threshold :  4\n",
      "should delete :  [6, 9, 7, 5]\n",
      "1 个完成了\n",
      "my answer is  levi ' s stadium in the san francisco bay area at santa clara , california\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 5, 9]\n",
      "2 个完成了\n",
      "my answer is  denver broncos\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 9]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 9, 5]\n",
      "3 个完成了\n",
      "my answer is  gold\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 5]\n",
      "threshold :  3\n",
      "should delete :  [6, 5, 9]\n",
      "threshold :  4\n",
      "should delete :  [6, 5, 9, 7]\n",
      "4 个完成了\n",
      "my answer is  golden anniversary\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 5]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 5, 7]\n",
      "5 个完成了\n",
      "my answer is  february 7 , 2016\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 9]\n",
      "threshold :  3\n",
      "should delete :  [6, 9, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 9, 5, 8]\n",
      "6 个完成了\n",
      "my answer is  american football conference\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 5, 9]\n",
      "7 个完成了\n",
      "my answer is  golden anniversary\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 5]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 5, 7]\n",
      "8 个完成了\n",
      "my answer is  american football conference\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 5, 9]\n",
      "9 个完成了\n",
      "my answer is  february 7 , 2016\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 9]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 9, 5]\n",
      "10 个完成了\n",
      "my answer is  denver broncos\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 5, 9]\n",
      "11 个完成了\n",
      "my answer is  levi ' s stadium\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 9]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 9, 5]\n",
      "12 个完成了\n",
      "my answer is  santa clara , california\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 9]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 9, 5]\n",
      "13 个完成了\n",
      "my answer is  super bowl l\n",
      "threshold :  0\n",
      "should delete :  [7]\n",
      "threshold :  1\n",
      "should delete :  [7]\n",
      "threshold :  2\n",
      "should delete :  [7, 6]\n",
      "threshold :  3\n",
      "should delete :  [7, 6, 9]\n",
      "threshold :  4\n",
      "should delete :  [7, 6, 9, 10]\n",
      "14 个完成了\n",
      "my answer is  2015\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 5]\n",
      "threshold :  3\n",
      "should delete :  [6, 5, 7]\n",
      "threshold :  4\n",
      "should delete :  [6, 5, 7, 9]\n",
      "15 个完成了\n",
      "my answer is  2016\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 9]\n",
      "threshold :  3\n",
      "should delete :  [6, 9, 8]\n",
      "threshold :  4\n",
      "should delete :  [6, 9, 8, 7]\n",
      "16 个完成了\n",
      "my answer is  santa clara , california\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 9]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 9, 5]\n",
      "17 个完成了\n",
      "my answer is  levi ' s stadium\n",
      "threshold :  0\n",
      "should delete :  [8]\n",
      "threshold :  1\n",
      "should delete :  [8]\n",
      "threshold :  2\n",
      "should delete :  [8, 6]\n",
      "threshold :  3\n",
      "should delete :  [8, 6, 9]\n",
      "threshold :  4\n",
      "should delete :  [8, 6, 9, 5]\n",
      "18 个完成了\n",
      "my answer is  24 – 10\n",
      "threshold :  0\n",
      "should delete :  [6]\n",
      "threshold :  1\n",
      "should delete :  [6]\n",
      "threshold :  2\n",
      "should delete :  [6, 8]\n",
      "threshold :  3\n",
      "should delete :  [6, 8, 5]\n",
      "threshold :  4\n",
      "should delete :  [6, 8, 5, 9]\n",
      "19 个完成了\n",
      "c_handle测试完成\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import difflib\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# replace <PATd:/spofrte/modeH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "# load model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "\"\"\"++++++++++++++++++这几个函数是计算f1 score 数值的，代码是抄的，千万不能改！+++++++++++++++++\"\"\"\n",
    "\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "\n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example -\n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "\n",
    "    return gold_answers\n",
    "\n",
    "\n",
    "\"\"\"+++++++++++++++++++++++++++++++++++\"\"\"\n",
    "\n",
    "\n",
    "def string_similar(s1, s2):\n",
    "    return difflib.SequenceMatcher(None, s1, s2).quick_ratio()\n",
    "\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids, attention_mask=attention_mask, )\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "ref_token_id = tokenizer.pad_token_id  # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id  # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id  # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)  # * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=token_type_ids,\n",
    "                                                 position_ids=position_ids)\n",
    "\n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "def predict_qt(question, text):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id,\n",
    "                                                                cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = '13'\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, \\\n",
    "                                       token_type_ids=token_type_ids, \\\n",
    "                                       position_ids=position_ids, \\\n",
    "                                       attention_mask=attention_mask)\n",
    "\n",
    "    #print('Question: ', question)\n",
    "    #print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1]))\n",
    "    return input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens,\n",
    "\n",
    "\n",
    "def explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores,\n",
    "            ground_truth, all_tokens, ):\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, model.bert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "                                                    baselines=ref_input_ids,\n",
    "                                                    additional_forward_args=(\n",
    "                                                        token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                    internal_batch_size=4,\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids,\n",
    "                                                additional_forward_args=(\n",
    "                                                    token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                internal_batch_size=4,\n",
    "                                                return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_start_sum,\n",
    "        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "        torch.argmax(start_scores),\n",
    "        torch.argmax(start_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_start_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_start)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_end_sum,\n",
    "        torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "        torch.argmax(end_scores),\n",
    "        torch.argmax(end_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_end_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_end)\n",
    "    # print(all_tokens)\n",
    "    #print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "    #viz.visualize_text([start_position_vis])\n",
    "\n",
    "    #print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "\n",
    "    #print(\"attributions_start_sum:   \", len(attributions_start_sum))\n",
    "    # print(\"all tokens:    \", len(all_tokens))\n",
    "\n",
    "    return all_tokens, attributions_start_sum\n",
    "\n",
    "\n",
    "def get_posneg(all_tokens, attributions_start_sum):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "    for i, j in enumerate(attributions_start_sum):\n",
    "        if j > 0:\n",
    "            positive.append(i)\n",
    "            # print('positive:',j)\n",
    "        ##print(all_tokens[i])\n",
    "        elif j < 0:\n",
    "            negative.append(i)\n",
    "            # print('negative:',j)\n",
    "            # print(all_tokens[i])\n",
    "        elif j == 0:\n",
    "            neutral.append(i)\n",
    "\n",
    "    s_pos = ''\n",
    "    s_neg = ''\n",
    "\n",
    "    # print(len(attributions_start_sum))\n",
    "    # print(len(positive))\n",
    "    # print(len(negative))\n",
    "\n",
    "    for i in positive:\n",
    "        s_pos += all_tokens[i] + ' '\n",
    "    # print(\"positive :\", s_pos)\n",
    "    for i in negative:\n",
    "        s_neg += all_tokens[i] + ' '\n",
    "    # print(\"negative :\", s_neg)\n",
    "    return positive, negative, neutral\n",
    "\n",
    "\n",
    "def separate_sentence(all_tokens):\n",
    "    sentence = {}\n",
    "    temp = []\n",
    "    num = 0\n",
    "    for i in range(len(all_tokens)):\n",
    "        if all_tokens[i] == \",\" or all_tokens[i] == \".\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[CLS]\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[SEP]\":\n",
    "            sentence[num] = temp\n",
    "            num = num + 1\n",
    "            temp = [all_tokens[i]]\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        else:\n",
    "            temp.append(all_tokens[i])\n",
    "    return sentence\n",
    "def gaussian_scores(scores):\n",
    "    # 使用高斯滤波替换贡献:\n",
    "    old_contri = []\n",
    "    for i in scores.values():\n",
    "        old_contri.append(i)\n",
    "\n",
    "    gaussian_contri = gaussian_filter(old_contri, sigma=5)\n",
    "    gaussin_scores = {}\n",
    "    index = 0\n",
    "    for i, j in scores.items():\n",
    "        gaussin_scores[i] = gaussian_contri[index]\n",
    "        index = index + 1\n",
    "    return gaussin_scores\n",
    "\n",
    "def get_sence_score(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = []\n",
    "    for k, v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores = {}\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = abs(attributions_start_sum[i].item())\n",
    "        except:\n",
    "            pass\n",
    "    #scores = gaussian_scores(scores)\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight += scores[word]\n",
    "        delete_sentence.append(sum_weight)\n",
    "        # print(sum_weight)\n",
    "    return delete_sentence\n",
    "def get_sence_gaussianscore(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = []\n",
    "    for k, v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores = {}\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "    scores = gaussian_scores(scores)\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight += scores[word]\n",
    "        delete_sentence.append(sum_weight)\n",
    "        # print(sum_weight)\n",
    "    return delete_sentence\n",
    "\n",
    "def get_delete(sentence):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = {}\n",
    "    for k, v in sentence.items():\n",
    "        # print(k,':',v)\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    # print(sentence_value)\n",
    "    scores = {}\n",
    "    # print(attributions_start_sum[0].item())\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            weight = 0\n",
    "\n",
    "            sum_weight += scores[word]\n",
    "            delete_sentence[i] = sum_weight\n",
    "    return delete_sentence\n",
    "\n",
    "\n",
    "def delete_sentence(sentence, li_delete_sentence):\n",
    "    for i, j in sentence.items():\n",
    "        if i in li_delete_sentence:\n",
    "            sentence[i] = []\n",
    "        else:\n",
    "            pass\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def rebuild_sentence(ori_sentence):\n",
    "    rebuild_str = \"\"\n",
    "    for i, j in ori_sentence.items():\n",
    "        for word in j:\n",
    "            rebuild_str += word\n",
    "            rebuild_str += \" \"\n",
    "    return rebuild_str\n",
    "\n",
    "\n",
    "def pred_explain(question, text):\n",
    "    input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens, = predict_qt(question, text)\n",
    "\n",
    "    all_tokens, attributions_start_sum = explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask,\n",
    "                                                 start_scores, end_scores, ground_truth, all_tokens, )\n",
    "\n",
    "    end_score = float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "    start_score = float(torch.max(torch.softmax(start_scores[0], dim=0)))\n",
    "\n",
    "    return all_tokens, attributions_start_sum, end_score, start_score, [torch.argmax(start_scores), torch.argmax(\n",
    "        end_scores) + 1], start_scores, end_scores\n",
    "\n",
    "\n",
    "def max_min(x, y, z):\n",
    "    max = min = x\n",
    "    i = 1\n",
    "    if y > max:\n",
    "        max = y\n",
    "        i = 2\n",
    "    else:\n",
    "        min = y\n",
    "    if z > max:\n",
    "        max = z\n",
    "        i = 3\n",
    "    else:\n",
    "        min = z\n",
    "    return (i)\n",
    "\n",
    "def analysis(f1, acc_s, acc_e, sun):\n",
    "    plt.plot(range(len(f1)), f1, \"--bo\", label=\"f1 score\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(acc_s)), acc_s)\n",
    "    plt.plot(range(len(acc_e)), acc_e)\n",
    "    plt.plot(range(len(sun)), sun)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cycle_prediction(cycle_num, question, text, s_answer):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(text,\n",
    "                                                                                                              question)\n",
    "\n",
    "    f1 = []\n",
    "    acc_s = []\n",
    "    acc_e = []\n",
    "    sun = []\n",
    "    ans = []\n",
    "    second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    second_answer = re.sub(r' ##', '', second_answer)\n",
    "    f1_score = compute_f1(second_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = rebuild_text(all_tokens, attributions_start_sum)\n",
    "\n",
    "        all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "        reanswer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        # print(start_acc, end_acc)\n",
    "        second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        # print(\"my answer is \", second_answer)\n",
    "        ans.append(second_answer)\n",
    "        # print(start_acc, end_acc)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "        pos_contri = 0\n",
    "        neg_contri = 0\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "\n",
    "        # print(acc_s, acc_e)\n",
    "        # print(acc_s, acc_e)\n",
    "\n",
    "    for i in range(len(acc_s)):\n",
    "        sun.append((acc_s[i] + acc_e[i]) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "def cascading_rebuild_text(all_tokens, attributions_start_sum):\n",
    "\n",
    "    li_sep = []\n",
    "    min_sensocer = 999\n",
    "    li_symbol = []\n",
    "    min_index = 999\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    sentence_score = get_sence_score(sentence, attributions_start_sum)\n",
    "    guassian_score = get_sence_gaussianscore(sentence, attributions_start_sum)\n",
    "\n",
    "    for i in range(len(sentence_score)):\n",
    "        if sentence_score[i] == 0:\n",
    "            li_symbol.append(i)\n",
    "\n",
    "    for i in li_symbol:\n",
    "        guassian_score[i] == 0\n",
    "    for i in range(len(guassian_score)):\n",
    "        if sentence_score[i] < min_sensocer and sentence_score[i] != 0:\n",
    "            min_sensocer = sentence_score[i]\n",
    "            min_index = i\n",
    "    print(\"should delete\", min_index, min_sensocer)\n",
    "\n",
    "    # temp = []\n",
    "    # for i in sentence_score:\n",
    "    #     temp.append(abs(i))\n",
    "    # sentence[sentence_score.index(min(temp))] = ''\n",
    "\n",
    "\n",
    "    sentence[min_index] = ''#删除贡献最小的句子\n",
    "    sentence[1] = ''#删除问题\n",
    "    retext = \"\"\n",
    "    for i, j in sentence.items():\n",
    "        for words in j:\n",
    "            retext = retext + words + \" \"\n",
    "    #这是清楚 ## 等模型引入的字符串\n",
    "    for m in re.finditer(r\"SEP\", retext):\n",
    "        li_sep.append(m.start())\n",
    "        li_sep.append(m.end())\n",
    "    retext = retext[li_sep[1] + 1: li_sep[2] - 1]\n",
    "    retext = re.sub(r' ##', '', retext)\n",
    "    return retext\n",
    "def cascading_min(data, min_id):\n",
    "    print(\"threshold : \", min_id)\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == 0:\n",
    "            data[i] = 999\n",
    "    d = {}\n",
    "    li_min = []\n",
    "    if min_id == 0:  # 设定一个空字典\n",
    "        for i, v in enumerate(data):  # 利用函数enumerate列出lt的每个元素下标i和元素v\n",
    "            d[v] = i  # 把v作为字典的键，v对应的值是i\n",
    "        data.sort()  # 运用sort函数对lt元素排\n",
    "        y = data[min_id]  # 此时lt中第二小的下标是1，求出对应的元素就是字典对应的键\n",
    "        return [d[y]]\n",
    "    if min_id != 0:\n",
    "        for i, v in enumerate(data):  # 利用函数enumerate列出lt的每个元素下标i和元素v\n",
    "            d[v] = i  # 把v作为字典的键，v对应的值是i\n",
    "        data.sort()  # 运用sort函数对lt元素排\n",
    "        try:\n",
    "            for i in range(min_id):\n",
    "                li_min.append(d[data[i]])  # 此时lt中第二小的下标是1，求出对应的元素就是字典对应的键\n",
    "        except:\n",
    "            pass\n",
    "        return li_min\n",
    "\n",
    "\n",
    "\n",
    "def independ_rebuild_text(all_tokens, attributions_start_sum, threshold):\n",
    "    li_sep = []\n",
    "    min_sensocer = 999\n",
    "    li_symbol = []\n",
    "    min_index = []\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    sentence_score = get_sence_score(sentence, attributions_start_sum)\n",
    "\n",
    "    min_index = cascading_min(sentence_score, threshold)\n",
    "    print(\"should delete : \", min_index)\n",
    "\n",
    "\n",
    "    # temp = []\n",
    "    # for i in sentence_score:\n",
    "    #     temp.append(abs(i))\n",
    "    # sentence[sentence_score.index(min(temp))] = ''\n",
    "\n",
    "    for i in min_index:\n",
    "        sentence[i] = \"\"#删除贡献最小的句子\n",
    "    sentence[1] = ''#删除问题\n",
    "    retext = \"\"\n",
    "    for i, j in sentence.items():\n",
    "        for words in j:\n",
    "            retext = retext + words + \" \"\n",
    "    #这是清楚 ## 等模型引入的字符串\n",
    "    for m in re.finditer(r\"SEP\", retext):\n",
    "        li_sep.append(m.start())\n",
    "        li_sep.append(m.end())\n",
    "    if len(li_sep) > 2:\n",
    "        retext = retext[li_sep[1] + 1: li_sep[2] - 1]\n",
    "    retext = re.sub(r' ##', '', retext)\n",
    "    return retext\n",
    "def independ_muti_pre(cycle_num, question, text, s_answer, pro_keep, pro_next):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(question, text)\n",
    "\n",
    "    first_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    first_answer = re.sub(r' ##', '', first_answer)\n",
    "    print(\"my answer is \", first_answer)\n",
    "    ans = []\n",
    "    acc_s= []\n",
    "    acc_e = []\n",
    "    f1 = []\n",
    "    sun = []\n",
    "    f1_score = compute_f1(first_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    acc_s.append(start_acc)\n",
    "    acc_e.append(end_acc)\n",
    "    sun.append((start_acc+end_acc)/2)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = independ_rebuild_text(all_tokens, attributions_start_sum, loop)\n",
    "\n",
    "\n",
    "        tokens, attributions, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "\n",
    "        second_answer = ' '.join(tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        ans.append(second_answer)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "        sun.append((start_acc + end_acc) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "\n",
    "def cascading_muti_pre(cycle_num, question, text, s_answer, pro_keep, pro_next):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(question, text)\n",
    "\n",
    "    first_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    first_answer = re.sub(r' ##', '', first_answer)\n",
    "    print(\"my answer is \", first_answer)\n",
    "    ans = []\n",
    "    acc_s= []\n",
    "    acc_e = []\n",
    "    f1 = []\n",
    "    sun = []\n",
    "    f1_score = compute_f1(first_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    acc_s.append(start_acc)\n",
    "    acc_e.append(end_acc)\n",
    "    sun.append((start_acc+end_acc)/2)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = cascading_rebuild_text(all_tokens, attributions_start_sum)\n",
    "\n",
    "\n",
    "        tokens, attributions, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "\n",
    "        second_answer = ' '.join(tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        ans.append(second_answer)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "        sun.append((start_acc + end_acc) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "\n",
    "def write_fil(filname, f1, acc_s, acc_e, sun):\n",
    "    c_handle = {}\n",
    "    c_handle[\"f1\"] = f1\n",
    "    c_handle[\"forword_pro\"] = acc_s\n",
    "    c_handle[\"backword_pro\"] = acc_e\n",
    "    c_handle[\"sun_pro\"] = sun\n",
    "    print(\"c_handle测试完成\")\n",
    "    with open(filname, \"a\")as f:\n",
    "        f.write(str(c_handle) + \"\\r\\n\")\n",
    "\n",
    "datasets = load_dataset('squad')\n",
    "C_f1 = []\n",
    "C_accs = []\n",
    "C_acce = []\n",
    "C_sun = []\n",
    "\n",
    "i_f1 = []\n",
    "i_accs = []\n",
    "i_acce = []\n",
    "i_sun = []\n",
    "c_handle = {}\n",
    "\n",
    "i_handle = {}\n",
    "\n",
    "# for i in range(len(datasets['validation'])):\n",
    "for i in range(20):\n",
    "    text = datasets['validation'][i]['context']\n",
    "    question = datasets['validation'][i]['question']\n",
    "    answers = datasets['validation'][i]['answers']\n",
    "    f1, acc_s, acc_e, sun = independ_muti_pre(5, question, text, answers['text'][0], 0.9, 0.7)\n",
    "    i_f1.append(f1)\n",
    "    i_accs.append(acc_s)\n",
    "    i_acce.append(acc_e)\n",
    "    i_sun.append(sun)\n",
    "    print(i, \"个完成了\")\n",
    "    write_fil(\"sliding_result.txt\", f1, acc_s, acc_e, sun)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c133999f0ce8d3c4aa177894441247ff4efac3487be3c31d2df0852d80fcfe89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('xai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
