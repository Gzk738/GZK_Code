{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/zikun/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0b239592114e9cb35078672b4139db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my answer is  denver broncos\n",
      "0.0\n",
      "0.12398601071497137\n",
      "0.0\n",
      "0.04677412863459155\n",
      "0.04622132419030428\n",
      "0.034614931548049115\n",
      "0.034981147032914085\n",
      "0.018136713045331362\n",
      "0.19068187545366672\n",
      "0.0336571474076904\n",
      "0.029539538052629828\n",
      "0.03641124630615647\n",
      "0.06531117616812439\n",
      "0.0\n",
      "[999, 999, 999, 0.04677412863459155, 0.04622132419030428, 0.034614931548049115, 0.034981147032914085, 0.018136713045331362, 0.19068187545366672, 0.0336571474076904, 0.029539538052629828, 0.03641124630615647, 0.06531117616812439, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12398601071497137\n",
      "0.0\n",
      "0.04677412863459155\n",
      "0.04622132419030428\n",
      "0.034614931548049115\n",
      "0.034981147032914085\n",
      "0.018136713045331362\n",
      "0.19068187545366672\n",
      "0.0336571474076904\n",
      "0.029539538052629828\n",
      "0.03641124630615647\n",
      "0.06531117616812439\n",
      "0.0\n",
      "[999, 999, 999, 0.04677412863459155, 0.04622132419030428, 0.034614931548049115, 0.034981147032914085, 0.018136713045331362, 0.19068187545366672, 0.0336571474076904, 0.029539538052629828, 0.03641124630615647, 0.06531117616812439, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12398601071497137\n",
      "0.0\n",
      "0.04677412863459155\n",
      "0.04622132419030428\n",
      "0.034614931548049115\n",
      "0.034981147032914085\n",
      "0.018136713045331362\n",
      "0.19068187545366672\n",
      "0.0336571474076904\n",
      "0.029539538052629828\n",
      "0.03641124630615647\n",
      "0.06531117616812439\n",
      "0.0\n",
      "[999, 999, 999, 0.04677412863459155, 0.04622132419030428, 0.034614931548049115, 0.034981147032914085, 0.018136713045331362, 0.19068187545366672, 0.0336571474076904, 0.029539538052629828, 0.03641124630615647, 0.06531117616812439, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12398601071497137\n",
      "0.0\n",
      "0.04677412863459155\n",
      "0.04622132419030428\n",
      "0.034614931548049115\n",
      "0.034981147032914085\n",
      "0.018136713045331362\n",
      "0.19068187545366672\n",
      "0.0336571474076904\n",
      "0.029539538052629828\n",
      "0.03641124630615647\n",
      "0.06531117616812439\n",
      "0.0\n",
      "[999, 999, 999, 0.04677412863459155, 0.04622132419030428, 0.034614931548049115, 0.034981147032914085, 0.018136713045331362, 0.19068187545366672, 0.0336571474076904, 0.029539538052629828, 0.03641124630615647, 0.06531117616812439, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12398601071497137\n",
      "0.0\n",
      "0.04677412863459155\n",
      "0.04622132419030428\n",
      "0.034614931548049115\n",
      "0.034981147032914085\n",
      "0.018136713045331362\n",
      "0.19068187545366672\n",
      "0.0336571474076904\n",
      "0.029539538052629828\n",
      "0.03641124630615647\n",
      "0.06531117616812439\n",
      "0.0\n",
      "[999, 999, 999, 0.04677412863459155, 0.04622132419030428, 0.034614931548049115, 0.034981147032914085, 0.018136713045331362, 0.19068187545366672, 0.0336571474076904, 0.029539538052629828, 0.03641124630615647, 0.06531117616812439, 999]\n",
      "should delete 7\n",
      "0 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  carolina panthers\n",
      "0.0\n",
      "0.13561314533485083\n",
      "0.0\n",
      "0.040224463167052533\n",
      "0.056866927074631826\n",
      "0.03465484430967254\n",
      "0.029737513180685283\n",
      "0.013287534537402326\n",
      "0.1470599049355839\n",
      "0.019709390142619986\n",
      "0.022282855879347734\n",
      "0.025457052905897518\n",
      "0.05262993111517905\n",
      "0.0\n",
      "[999, 999, 999, 0.040224463167052533, 0.056866927074631826, 0.03465484430967254, 0.029737513180685283, 0.013287534537402326, 0.1470599049355839, 0.019709390142619986, 0.022282855879347734, 0.025457052905897518, 0.05262993111517905, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.13561314533485083\n",
      "0.0\n",
      "0.040224463167052533\n",
      "0.056866927074631826\n",
      "0.03465484430967254\n",
      "0.029737513180685283\n",
      "0.013287534537402326\n",
      "0.1470599049355839\n",
      "0.019709390142619986\n",
      "0.022282855879347734\n",
      "0.025457052905897518\n",
      "0.05262993111517905\n",
      "0.0\n",
      "[999, 999, 999, 0.040224463167052533, 0.056866927074631826, 0.03465484430967254, 0.029737513180685283, 0.013287534537402326, 0.1470599049355839, 0.019709390142619986, 0.022282855879347734, 0.025457052905897518, 0.05262993111517905, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.13561314533485083\n",
      "0.0\n",
      "0.040224463167052533\n",
      "0.056866927074631826\n",
      "0.03465484430967254\n",
      "0.029737513180685283\n",
      "0.013287534537402326\n",
      "0.1470599049355839\n",
      "0.019709390142619986\n",
      "0.022282855879347734\n",
      "0.025457052905897518\n",
      "0.05262993111517905\n",
      "0.0\n",
      "[999, 999, 999, 0.040224463167052533, 0.056866927074631826, 0.03465484430967254, 0.029737513180685283, 0.013287534537402326, 0.1470599049355839, 0.019709390142619986, 0.022282855879347734, 0.025457052905897518, 0.05262993111517905, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.13561314533485083\n",
      "0.0\n",
      "0.040224463167052533\n",
      "0.056866927074631826\n",
      "0.03465484430967254\n",
      "0.029737513180685283\n",
      "0.013287534537402326\n",
      "0.1470599049355839\n",
      "0.019709390142619986\n",
      "0.022282855879347734\n",
      "0.025457052905897518\n",
      "0.05262993111517905\n",
      "0.0\n",
      "[999, 999, 999, 0.040224463167052533, 0.056866927074631826, 0.03465484430967254, 0.029737513180685283, 0.013287534537402326, 0.1470599049355839, 0.019709390142619986, 0.022282855879347734, 0.025457052905897518, 0.05262993111517905, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.13561314533485083\n",
      "0.0\n",
      "0.040224463167052533\n",
      "0.056866927074631826\n",
      "0.03465484430967254\n",
      "0.029737513180685283\n",
      "0.013287534537402326\n",
      "0.1470599049355839\n",
      "0.019709390142619986\n",
      "0.022282855879347734\n",
      "0.025457052905897518\n",
      "0.05262993111517905\n",
      "0.0\n",
      "[999, 999, 999, 0.040224463167052533, 0.056866927074631826, 0.03465484430967254, 0.029737513180685283, 0.013287534537402326, 0.1470599049355839, 0.019709390142619986, 0.022282855879347734, 0.025457052905897518, 0.05262993111517905, 999]\n",
      "should delete 7\n",
      "1 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  levi ' s stadium in the san francisco bay area at santa clara , california\n",
      "0.0\n",
      "0.19216769014226004\n",
      "0.0\n",
      "0.03596144862445179\n",
      "0.031171668436499548\n",
      "0.0397352949042939\n",
      "0.03895760886239393\n",
      "0.030589256231372198\n",
      "0.04845251189425889\n",
      "0.04429154390955027\n",
      "0.036302989556368424\n",
      "0.04992419530368095\n",
      "0.02645686585666731\n",
      "0.0\n",
      "[999, 999, 999, 0.03596144862445179, 0.031171668436499548, 0.0397352949042939, 0.03895760886239393, 0.030589256231372198, 0.04845251189425889, 0.04429154390955027, 0.036302989556368424, 0.04992419530368095, 0.02645686585666731, 999]\n",
      "should delete 12\n",
      "0.0\n",
      "0.19216769014226004\n",
      "0.0\n",
      "0.03596144862445179\n",
      "0.031171668436499548\n",
      "0.0397352949042939\n",
      "0.03895760886239393\n",
      "0.030589256231372198\n",
      "0.04845251189425889\n",
      "0.04429154390955027\n",
      "0.036302989556368424\n",
      "0.04992419530368095\n",
      "0.02645686585666731\n",
      "0.0\n",
      "[999, 999, 999, 0.03596144862445179, 0.031171668436499548, 0.0397352949042939, 0.03895760886239393, 0.030589256231372198, 0.04845251189425889, 0.04429154390955027, 0.036302989556368424, 0.04992419530368095, 0.02645686585666731, 999]\n",
      "should delete 12\n",
      "0.0\n",
      "0.19216769014226004\n",
      "0.0\n",
      "0.03596144862445179\n",
      "0.031171668436499548\n",
      "0.0397352949042939\n",
      "0.03895760886239393\n",
      "0.030589256231372198\n",
      "0.04845251189425889\n",
      "0.04429154390955027\n",
      "0.036302989556368424\n",
      "0.04992419530368095\n",
      "0.02645686585666731\n",
      "0.0\n",
      "[999, 999, 999, 0.03596144862445179, 0.031171668436499548, 0.0397352949042939, 0.03895760886239393, 0.030589256231372198, 0.04845251189425889, 0.04429154390955027, 0.036302989556368424, 0.04992419530368095, 0.02645686585666731, 999]\n",
      "should delete 12\n",
      "0.0\n",
      "0.19216769014226004\n",
      "0.0\n",
      "0.03596144862445179\n",
      "0.031171668436499548\n",
      "0.0397352949042939\n",
      "0.03895760886239393\n",
      "0.030589256231372198\n",
      "0.04845251189425889\n",
      "0.04429154390955027\n",
      "0.036302989556368424\n",
      "0.04992419530368095\n",
      "0.02645686585666731\n",
      "0.0\n",
      "[999, 999, 999, 0.03596144862445179, 0.031171668436499548, 0.0397352949042939, 0.03895760886239393, 0.030589256231372198, 0.04845251189425889, 0.04429154390955027, 0.036302989556368424, 0.04992419530368095, 0.02645686585666731, 999]\n",
      "should delete 12\n",
      "0.0\n",
      "0.19216769014226004\n",
      "0.0\n",
      "0.03596144862445179\n",
      "0.031171668436499548\n",
      "0.0397352949042939\n",
      "0.03895760886239393\n",
      "0.030589256231372198\n",
      "0.04845251189425889\n",
      "0.04429154390955027\n",
      "0.036302989556368424\n",
      "0.04992419530368095\n",
      "0.02645686585666731\n",
      "0.0\n",
      "[999, 999, 999, 0.03596144862445179, 0.031171668436499548, 0.0397352949042939, 0.03895760886239393, 0.030589256231372198, 0.04845251189425889, 0.04429154390955027, 0.036302989556368424, 0.04992419530368095, 0.02645686585666731, 999]\n",
      "should delete 12\n",
      "2 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  denver broncos\n",
      "0.0\n",
      "0.11942381857289414\n",
      "0.0\n",
      "0.02792816972837014\n",
      "0.030535380489269872\n",
      "0.01923886626742654\n",
      "0.040173179737935834\n",
      "0.029306266853553378\n",
      "0.020353873679133362\n",
      "0.01593847251255022\n",
      "0.011829230418068699\n",
      "0.014345215783772878\n",
      "0.016273559307463263\n",
      "0.0\n",
      "[999, 999, 999, 0.02792816972837014, 0.030535380489269872, 0.01923886626742654, 0.040173179737935834, 0.029306266853553378, 0.020353873679133362, 0.01593847251255022, 0.011829230418068699, 0.014345215783772878, 0.016273559307463263, 999]\n",
      "should delete 10\n",
      "0.0\n",
      "0.11942381857289414\n",
      "0.0\n",
      "0.02792816972837014\n",
      "0.030535380489269872\n",
      "0.01923886626742654\n",
      "0.040173179737935834\n",
      "0.029306266853553378\n",
      "0.020353873679133362\n",
      "0.01593847251255022\n",
      "0.011829230418068699\n",
      "0.014345215783772878\n",
      "0.016273559307463263\n",
      "0.0\n",
      "[999, 999, 999, 0.02792816972837014, 0.030535380489269872, 0.01923886626742654, 0.040173179737935834, 0.029306266853553378, 0.020353873679133362, 0.01593847251255022, 0.011829230418068699, 0.014345215783772878, 0.016273559307463263, 999]\n",
      "should delete 10\n",
      "0.0\n",
      "0.11942381857289414\n",
      "0.0\n",
      "0.02792816972837014\n",
      "0.030535380489269872\n",
      "0.01923886626742654\n",
      "0.040173179737935834\n",
      "0.029306266853553378\n",
      "0.020353873679133362\n",
      "0.01593847251255022\n",
      "0.011829230418068699\n",
      "0.014345215783772878\n",
      "0.016273559307463263\n",
      "0.0\n",
      "[999, 999, 999, 0.02792816972837014, 0.030535380489269872, 0.01923886626742654, 0.040173179737935834, 0.029306266853553378, 0.020353873679133362, 0.01593847251255022, 0.011829230418068699, 0.014345215783772878, 0.016273559307463263, 999]\n",
      "should delete 10\n",
      "0.0\n",
      "0.11942381857289414\n",
      "0.0\n",
      "0.02792816972837014\n",
      "0.030535380489269872\n",
      "0.01923886626742654\n",
      "0.040173179737935834\n",
      "0.029306266853553378\n",
      "0.020353873679133362\n",
      "0.01593847251255022\n",
      "0.011829230418068699\n",
      "0.014345215783772878\n",
      "0.016273559307463263\n",
      "0.0\n",
      "[999, 999, 999, 0.02792816972837014, 0.030535380489269872, 0.01923886626742654, 0.040173179737935834, 0.029306266853553378, 0.020353873679133362, 0.01593847251255022, 0.011829230418068699, 0.014345215783772878, 0.016273559307463263, 999]\n",
      "should delete 10\n",
      "0.0\n",
      "0.11942381857289414\n",
      "0.0\n",
      "0.02792816972837014\n",
      "0.030535380489269872\n",
      "0.01923886626742654\n",
      "0.040173179737935834\n",
      "0.029306266853553378\n",
      "0.020353873679133362\n",
      "0.01593847251255022\n",
      "0.011829230418068699\n",
      "0.014345215783772878\n",
      "0.016273559307463263\n",
      "0.0\n",
      "[999, 999, 999, 0.02792816972837014, 0.030535380489269872, 0.01923886626742654, 0.040173179737935834, 0.029306266853553378, 0.020353873679133362, 0.01593847251255022, 0.011829230418068699, 0.014345215783772878, 0.016273559307463263, 999]\n",
      "should delete 10\n",
      "3 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  gold\n",
      "0.0\n",
      "0.10066440448644054\n",
      "0.0\n",
      "0.05040999693429492\n",
      "0.039998063030787116\n",
      "0.027514036546918332\n",
      "0.019989547527143204\n",
      "0.0263262141001498\n",
      "0.21240846153351756\n",
      "0.03395099961126025\n",
      "0.09565596209212367\n",
      "0.0313824905996017\n",
      "0.07092650248320795\n",
      "0.0\n",
      "[999, 999, 999, 0.05040999693429492, 0.039998063030787116, 0.027514036546918332, 0.019989547527143204, 0.0263262141001498, 0.21240846153351756, 0.03395099961126025, 0.09565596209212367, 0.0313824905996017, 0.07092650248320795, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.10066440448644054\n",
      "0.0\n",
      "0.05040999693429492\n",
      "0.039998063030787116\n",
      "0.027514036546918332\n",
      "0.019989547527143204\n",
      "0.0263262141001498\n",
      "0.21240846153351756\n",
      "0.03395099961126025\n",
      "0.09565596209212367\n",
      "0.0313824905996017\n",
      "0.07092650248320795\n",
      "0.0\n",
      "[999, 999, 999, 0.05040999693429492, 0.039998063030787116, 0.027514036546918332, 0.019989547527143204, 0.0263262141001498, 0.21240846153351756, 0.03395099961126025, 0.09565596209212367, 0.0313824905996017, 0.07092650248320795, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.10066440448644054\n",
      "0.0\n",
      "0.05040999693429492\n",
      "0.039998063030787116\n",
      "0.027514036546918332\n",
      "0.019989547527143204\n",
      "0.0263262141001498\n",
      "0.21240846153351756\n",
      "0.03395099961126025\n",
      "0.09565596209212367\n",
      "0.0313824905996017\n",
      "0.07092650248320795\n",
      "0.0\n",
      "[999, 999, 999, 0.05040999693429492, 0.039998063030787116, 0.027514036546918332, 0.019989547527143204, 0.0263262141001498, 0.21240846153351756, 0.03395099961126025, 0.09565596209212367, 0.0313824905996017, 0.07092650248320795, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.10066440448644054\n",
      "0.0\n",
      "0.05040999693429492\n",
      "0.039998063030787116\n",
      "0.027514036546918332\n",
      "0.019989547527143204\n",
      "0.0263262141001498\n",
      "0.21240846153351756\n",
      "0.03395099961126025\n",
      "0.09565596209212367\n",
      "0.0313824905996017\n",
      "0.07092650248320795\n",
      "0.0\n",
      "[999, 999, 999, 0.05040999693429492, 0.039998063030787116, 0.027514036546918332, 0.019989547527143204, 0.0263262141001498, 0.21240846153351756, 0.03395099961126025, 0.09565596209212367, 0.0313824905996017, 0.07092650248320795, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.10066440448644054\n",
      "0.0\n",
      "0.05040999693429492\n",
      "0.039998063030787116\n",
      "0.027514036546918332\n",
      "0.019989547527143204\n",
      "0.0263262141001498\n",
      "0.21240846153351756\n",
      "0.03395099961126025\n",
      "0.09565596209212367\n",
      "0.0313824905996017\n",
      "0.07092650248320795\n",
      "0.0\n",
      "[999, 999, 999, 0.05040999693429492, 0.039998063030787116, 0.027514036546918332, 0.019989547527143204, 0.0263262141001498, 0.21240846153351756, 0.03395099961126025, 0.09565596209212367, 0.0313824905996017, 0.07092650248320795, 999]\n",
      "should delete 6\n",
      "4 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  golden anniversary\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "5 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  february 7 , 2016\n",
      "0.0\n",
      "0.08568376714331796\n",
      "0.0\n",
      "0.04917154100791466\n",
      "0.03511864615515194\n",
      "0.03701212901919133\n",
      "0.0642806322477011\n",
      "0.031617900186827815\n",
      "0.1548753539255469\n",
      "0.030229646620661303\n",
      "0.03491779565905038\n",
      "0.028420548071506888\n",
      "0.06458860766060777\n",
      "0.0\n",
      "[999, 999, 999, 0.04917154100791466, 0.03511864615515194, 0.03701212901919133, 0.0642806322477011, 0.031617900186827815, 0.1548753539255469, 0.030229646620661303, 0.03491779565905038, 0.028420548071506888, 0.06458860766060777, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.08568376714331796\n",
      "0.0\n",
      "0.04917154100791466\n",
      "0.03511864615515194\n",
      "0.03701212901919133\n",
      "0.0642806322477011\n",
      "0.031617900186827815\n",
      "0.1548753539255469\n",
      "0.030229646620661303\n",
      "0.03491779565905038\n",
      "0.028420548071506888\n",
      "0.06458860766060777\n",
      "0.0\n",
      "[999, 999, 999, 0.04917154100791466, 0.03511864615515194, 0.03701212901919133, 0.0642806322477011, 0.031617900186827815, 0.1548753539255469, 0.030229646620661303, 0.03491779565905038, 0.028420548071506888, 0.06458860766060777, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.08568376714331796\n",
      "0.0\n",
      "0.04917154100791466\n",
      "0.03511864615515194\n",
      "0.03701212901919133\n",
      "0.0642806322477011\n",
      "0.031617900186827815\n",
      "0.1548753539255469\n",
      "0.030229646620661303\n",
      "0.03491779565905038\n",
      "0.028420548071506888\n",
      "0.06458860766060777\n",
      "0.0\n",
      "[999, 999, 999, 0.04917154100791466, 0.03511864615515194, 0.03701212901919133, 0.0642806322477011, 0.031617900186827815, 0.1548753539255469, 0.030229646620661303, 0.03491779565905038, 0.028420548071506888, 0.06458860766060777, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.08568376714331796\n",
      "0.0\n",
      "0.04917154100791466\n",
      "0.03511864615515194\n",
      "0.03701212901919133\n",
      "0.0642806322477011\n",
      "0.031617900186827815\n",
      "0.1548753539255469\n",
      "0.030229646620661303\n",
      "0.03491779565905038\n",
      "0.028420548071506888\n",
      "0.06458860766060777\n",
      "0.0\n",
      "[999, 999, 999, 0.04917154100791466, 0.03511864615515194, 0.03701212901919133, 0.0642806322477011, 0.031617900186827815, 0.1548753539255469, 0.030229646620661303, 0.03491779565905038, 0.028420548071506888, 0.06458860766060777, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.08568376714331796\n",
      "0.0\n",
      "0.04917154100791466\n",
      "0.03511864615515194\n",
      "0.03701212901919133\n",
      "0.0642806322477011\n",
      "0.031617900186827815\n",
      "0.1548753539255469\n",
      "0.030229646620661303\n",
      "0.03491779565905038\n",
      "0.028420548071506888\n",
      "0.06458860766060777\n",
      "0.0\n",
      "[999, 999, 999, 0.04917154100791466, 0.03511864615515194, 0.03701212901919133, 0.0642806322477011, 0.031617900186827815, 0.1548753539255469, 0.030229646620661303, 0.03491779565905038, 0.028420548071506888, 0.06458860766060777, 999]\n",
      "should delete 11\n",
      "6 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  american football conference\n",
      "0.0\n",
      "0.18102235322908125\n",
      "0.0\n",
      "0.01729210387039658\n",
      "0.01697505291943797\n",
      "0.013707985355093651\n",
      "0.012801994998459965\n",
      "0.011927673775021285\n",
      "0.03161559037928728\n",
      "0.01767454890206193\n",
      "0.016238938574572512\n",
      "0.025210681764766645\n",
      "0.02004748456913971\n",
      "0.0\n",
      "[999, 999, 999, 0.01729210387039658, 0.01697505291943797, 0.013707985355093651, 0.012801994998459965, 0.011927673775021285, 0.03161559037928728, 0.01767454890206193, 0.016238938574572512, 0.025210681764766645, 0.02004748456913971, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.18102235322908125\n",
      "0.0\n",
      "0.01729210387039658\n",
      "0.01697505291943797\n",
      "0.013707985355093651\n",
      "0.012801994998459965\n",
      "0.011927673775021285\n",
      "0.03161559037928728\n",
      "0.01767454890206193\n",
      "0.016238938574572512\n",
      "0.025210681764766645\n",
      "0.02004748456913971\n",
      "0.0\n",
      "[999, 999, 999, 0.01729210387039658, 0.01697505291943797, 0.013707985355093651, 0.012801994998459965, 0.011927673775021285, 0.03161559037928728, 0.01767454890206193, 0.016238938574572512, 0.025210681764766645, 0.02004748456913971, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.18102235322908125\n",
      "0.0\n",
      "0.01729210387039658\n",
      "0.01697505291943797\n",
      "0.013707985355093651\n",
      "0.012801994998459965\n",
      "0.011927673775021285\n",
      "0.03161559037928728\n",
      "0.01767454890206193\n",
      "0.016238938574572512\n",
      "0.025210681764766645\n",
      "0.02004748456913971\n",
      "0.0\n",
      "[999, 999, 999, 0.01729210387039658, 0.01697505291943797, 0.013707985355093651, 0.012801994998459965, 0.011927673775021285, 0.03161559037928728, 0.01767454890206193, 0.016238938574572512, 0.025210681764766645, 0.02004748456913971, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.18102235322908125\n",
      "0.0\n",
      "0.01729210387039658\n",
      "0.01697505291943797\n",
      "0.013707985355093651\n",
      "0.012801994998459965\n",
      "0.011927673775021285\n",
      "0.03161559037928728\n",
      "0.01767454890206193\n",
      "0.016238938574572512\n",
      "0.025210681764766645\n",
      "0.02004748456913971\n",
      "0.0\n",
      "[999, 999, 999, 0.01729210387039658, 0.01697505291943797, 0.013707985355093651, 0.012801994998459965, 0.011927673775021285, 0.03161559037928728, 0.01767454890206193, 0.016238938574572512, 0.025210681764766645, 0.02004748456913971, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.18102235322908125\n",
      "0.0\n",
      "0.01729210387039658\n",
      "0.01697505291943797\n",
      "0.013707985355093651\n",
      "0.012801994998459965\n",
      "0.011927673775021285\n",
      "0.03161559037928728\n",
      "0.01767454890206193\n",
      "0.016238938574572512\n",
      "0.025210681764766645\n",
      "0.02004748456913971\n",
      "0.0\n",
      "[999, 999, 999, 0.01729210387039658, 0.01697505291943797, 0.013707985355093651, 0.012801994998459965, 0.011927673775021285, 0.03161559037928728, 0.01767454890206193, 0.016238938574572512, 0.025210681764766645, 0.02004748456913971, 999]\n",
      "should delete 7\n",
      "7 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  golden anniversary\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.08555107925326522\n",
      "0.0\n",
      "0.03366695399556278\n",
      "0.023497517832176254\n",
      "0.01958481209277273\n",
      "0.03982220086499643\n",
      "0.012683929791071278\n",
      "0.017216015512107115\n",
      "0.05900394286760807\n",
      "0.09120031221188384\n",
      "0.04161976968954009\n",
      "0.0350831004467576\n",
      "0.0\n",
      "[999, 999, 999, 0.03366695399556278, 0.023497517832176254, 0.01958481209277273, 0.03982220086499643, 0.012683929791071278, 0.017216015512107115, 0.05900394286760807, 0.09120031221188384, 0.04161976968954009, 0.0350831004467576, 999]\n",
      "should delete 7\n",
      "8 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  american football conference\n",
      "0.0\n",
      "0.1919774265487327\n",
      "0.0\n",
      "0.021478938173216274\n",
      "0.02455201964004153\n",
      "0.020092654698511573\n",
      "0.026615323220328956\n",
      "0.04221984449795026\n",
      "0.0471722090096631\n",
      "0.024391951535139875\n",
      "0.020890802895965264\n",
      "0.02552701175039485\n",
      "0.02650755582960564\n",
      "0.0\n",
      "[999, 999, 999, 0.021478938173216274, 0.02455201964004153, 0.020092654698511573, 0.026615323220328956, 0.04221984449795026, 0.0471722090096631, 0.024391951535139875, 0.020890802895965264, 0.02552701175039485, 0.02650755582960564, 999]\n",
      "should delete 5\n",
      "0.0\n",
      "0.1919774265487327\n",
      "0.0\n",
      "0.021478938173216274\n",
      "0.02455201964004153\n",
      "0.020092654698511573\n",
      "0.026615323220328956\n",
      "0.04221984449795026\n",
      "0.0471722090096631\n",
      "0.024391951535139875\n",
      "0.020890802895965264\n",
      "0.02552701175039485\n",
      "0.02650755582960564\n",
      "0.0\n",
      "[999, 999, 999, 0.021478938173216274, 0.02455201964004153, 0.020092654698511573, 0.026615323220328956, 0.04221984449795026, 0.0471722090096631, 0.024391951535139875, 0.020890802895965264, 0.02552701175039485, 0.02650755582960564, 999]\n",
      "should delete 5\n",
      "0.0\n",
      "0.1919774265487327\n",
      "0.0\n",
      "0.021478938173216274\n",
      "0.02455201964004153\n",
      "0.020092654698511573\n",
      "0.026615323220328956\n",
      "0.04221984449795026\n",
      "0.0471722090096631\n",
      "0.024391951535139875\n",
      "0.020890802895965264\n",
      "0.02552701175039485\n",
      "0.02650755582960564\n",
      "0.0\n",
      "[999, 999, 999, 0.021478938173216274, 0.02455201964004153, 0.020092654698511573, 0.026615323220328956, 0.04221984449795026, 0.0471722090096631, 0.024391951535139875, 0.020890802895965264, 0.02552701175039485, 0.02650755582960564, 999]\n",
      "should delete 5\n",
      "0.0\n",
      "0.1919774265487327\n",
      "0.0\n",
      "0.021478938173216274\n",
      "0.02455201964004153\n",
      "0.020092654698511573\n",
      "0.026615323220328956\n",
      "0.04221984449795026\n",
      "0.0471722090096631\n",
      "0.024391951535139875\n",
      "0.020890802895965264\n",
      "0.02552701175039485\n",
      "0.02650755582960564\n",
      "0.0\n",
      "[999, 999, 999, 0.021478938173216274, 0.02455201964004153, 0.020092654698511573, 0.026615323220328956, 0.04221984449795026, 0.0471722090096631, 0.024391951535139875, 0.020890802895965264, 0.02552701175039485, 0.02650755582960564, 999]\n",
      "should delete 5\n",
      "0.0\n",
      "0.1919774265487327\n",
      "0.0\n",
      "0.021478938173216274\n",
      "0.02455201964004153\n",
      "0.020092654698511573\n",
      "0.026615323220328956\n",
      "0.04221984449795026\n",
      "0.0471722090096631\n",
      "0.024391951535139875\n",
      "0.020890802895965264\n",
      "0.02552701175039485\n",
      "0.02650755582960564\n",
      "0.0\n",
      "[999, 999, 999, 0.021478938173216274, 0.02455201964004153, 0.020092654698511573, 0.026615323220328956, 0.04221984449795026, 0.0471722090096631, 0.024391951535139875, 0.020890802895965264, 0.02552701175039485, 0.02650755582960564, 999]\n",
      "should delete 5\n",
      "9 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  february 7 , 2016\n",
      "0.0\n",
      "0.12639686098287486\n",
      "0.0\n",
      "0.049564814616785524\n",
      "0.042302069133100674\n",
      "0.049534966776278916\n",
      "0.05841899639137396\n",
      "0.03295583289151501\n",
      "0.11260355066445887\n",
      "0.037357946346749875\n",
      "0.03389249155907695\n",
      "0.0402713235629416\n",
      "0.06382679541044504\n",
      "0.0\n",
      "[999, 999, 999, 0.049564814616785524, 0.042302069133100674, 0.049534966776278916, 0.05841899639137396, 0.03295583289151501, 0.11260355066445887, 0.037357946346749875, 0.03389249155907695, 0.0402713235629416, 0.06382679541044504, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12639686098287486\n",
      "0.0\n",
      "0.049564814616785524\n",
      "0.042302069133100674\n",
      "0.049534966776278916\n",
      "0.05841899639137396\n",
      "0.03295583289151501\n",
      "0.11260355066445887\n",
      "0.037357946346749875\n",
      "0.03389249155907695\n",
      "0.0402713235629416\n",
      "0.06382679541044504\n",
      "0.0\n",
      "[999, 999, 999, 0.049564814616785524, 0.042302069133100674, 0.049534966776278916, 0.05841899639137396, 0.03295583289151501, 0.11260355066445887, 0.037357946346749875, 0.03389249155907695, 0.0402713235629416, 0.06382679541044504, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12639686098287486\n",
      "0.0\n",
      "0.049564814616785524\n",
      "0.042302069133100674\n",
      "0.049534966776278916\n",
      "0.05841899639137396\n",
      "0.03295583289151501\n",
      "0.11260355066445887\n",
      "0.037357946346749875\n",
      "0.03389249155907695\n",
      "0.0402713235629416\n",
      "0.06382679541044504\n",
      "0.0\n",
      "[999, 999, 999, 0.049564814616785524, 0.042302069133100674, 0.049534966776278916, 0.05841899639137396, 0.03295583289151501, 0.11260355066445887, 0.037357946346749875, 0.03389249155907695, 0.0402713235629416, 0.06382679541044504, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12639686098287486\n",
      "0.0\n",
      "0.049564814616785524\n",
      "0.042302069133100674\n",
      "0.049534966776278916\n",
      "0.05841899639137396\n",
      "0.03295583289151501\n",
      "0.11260355066445887\n",
      "0.037357946346749875\n",
      "0.03389249155907695\n",
      "0.0402713235629416\n",
      "0.06382679541044504\n",
      "0.0\n",
      "[999, 999, 999, 0.049564814616785524, 0.042302069133100674, 0.049534966776278916, 0.05841899639137396, 0.03295583289151501, 0.11260355066445887, 0.037357946346749875, 0.03389249155907695, 0.0402713235629416, 0.06382679541044504, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.12639686098287486\n",
      "0.0\n",
      "0.049564814616785524\n",
      "0.042302069133100674\n",
      "0.049534966776278916\n",
      "0.05841899639137396\n",
      "0.03295583289151501\n",
      "0.11260355066445887\n",
      "0.037357946346749875\n",
      "0.03389249155907695\n",
      "0.0402713235629416\n",
      "0.06382679541044504\n",
      "0.0\n",
      "[999, 999, 999, 0.049564814616785524, 0.042302069133100674, 0.049534966776278916, 0.05841899639137396, 0.03295583289151501, 0.11260355066445887, 0.037357946346749875, 0.03389249155907695, 0.0402713235629416, 0.06382679541044504, 999]\n",
      "should delete 7\n",
      "10 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  denver broncos\n",
      "0.0\n",
      "0.11366511853520939\n",
      "0.0\n",
      "0.04486089230929162\n",
      "0.06339369009937348\n",
      "0.025186263884607915\n",
      "0.011251103991245038\n",
      "0.03455936190194811\n",
      "0.032104259271831075\n",
      "0.039439501040609254\n",
      "0.02130197043539921\n",
      "0.03898463999586617\n",
      "0.03635263454902273\n",
      "0.0\n",
      "[999, 999, 999, 0.04486089230929162, 0.06339369009937348, 0.025186263884607915, 0.011251103991245038, 0.03455936190194811, 0.032104259271831075, 0.039439501040609254, 0.02130197043539921, 0.03898463999586617, 0.03635263454902273, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.11366511853520939\n",
      "0.0\n",
      "0.04486089230929162\n",
      "0.06339369009937348\n",
      "0.025186263884607915\n",
      "0.011251103991245038\n",
      "0.03455936190194811\n",
      "0.032104259271831075\n",
      "0.039439501040609254\n",
      "0.02130197043539921\n",
      "0.03898463999586617\n",
      "0.03635263454902273\n",
      "0.0\n",
      "[999, 999, 999, 0.04486089230929162, 0.06339369009937348, 0.025186263884607915, 0.011251103991245038, 0.03455936190194811, 0.032104259271831075, 0.039439501040609254, 0.02130197043539921, 0.03898463999586617, 0.03635263454902273, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.11366511853520939\n",
      "0.0\n",
      "0.04486089230929162\n",
      "0.06339369009937348\n",
      "0.025186263884607915\n",
      "0.011251103991245038\n",
      "0.03455936190194811\n",
      "0.032104259271831075\n",
      "0.039439501040609254\n",
      "0.02130197043539921\n",
      "0.03898463999586617\n",
      "0.03635263454902273\n",
      "0.0\n",
      "[999, 999, 999, 0.04486089230929162, 0.06339369009937348, 0.025186263884607915, 0.011251103991245038, 0.03455936190194811, 0.032104259271831075, 0.039439501040609254, 0.02130197043539921, 0.03898463999586617, 0.03635263454902273, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.11366511853520939\n",
      "0.0\n",
      "0.04486089230929162\n",
      "0.06339369009937348\n",
      "0.025186263884607915\n",
      "0.011251103991245038\n",
      "0.03455936190194811\n",
      "0.032104259271831075\n",
      "0.039439501040609254\n",
      "0.02130197043539921\n",
      "0.03898463999586617\n",
      "0.03635263454902273\n",
      "0.0\n",
      "[999, 999, 999, 0.04486089230929162, 0.06339369009937348, 0.025186263884607915, 0.011251103991245038, 0.03455936190194811, 0.032104259271831075, 0.039439501040609254, 0.02130197043539921, 0.03898463999586617, 0.03635263454902273, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.11366511853520939\n",
      "0.0\n",
      "0.04486089230929162\n",
      "0.06339369009937348\n",
      "0.025186263884607915\n",
      "0.011251103991245038\n",
      "0.03455936190194811\n",
      "0.032104259271831075\n",
      "0.039439501040609254\n",
      "0.02130197043539921\n",
      "0.03898463999586617\n",
      "0.03635263454902273\n",
      "0.0\n",
      "[999, 999, 999, 0.04486089230929162, 0.06339369009937348, 0.025186263884607915, 0.011251103991245038, 0.03455936190194811, 0.032104259271831075, 0.039439501040609254, 0.02130197043539921, 0.03898463999586617, 0.03635263454902273, 999]\n",
      "should delete 6\n",
      "11 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  levi ' s stadium\n",
      "0.0\n",
      "0.06950750730939279\n",
      "0.0\n",
      "0.05119393640181146\n",
      "0.04801154983757769\n",
      "0.08663193802960224\n",
      "0.061847432433678684\n",
      "0.07059140609904008\n",
      "0.1211303337610549\n",
      "0.07172813678793923\n",
      "0.05593734157850083\n",
      "0.049005055257414325\n",
      "0.050317033309075825\n",
      "0.0\n",
      "[999, 999, 999, 0.05119393640181146, 0.04801154983757769, 0.08663193802960224, 0.061847432433678684, 0.07059140609904008, 0.1211303337610549, 0.07172813678793923, 0.05593734157850083, 0.049005055257414325, 0.050317033309075825, 999]\n",
      "should delete 4\n",
      "0.0\n",
      "0.06950750730939279\n",
      "0.0\n",
      "0.05119393640181146\n",
      "0.04801154983757769\n",
      "0.08663193802960224\n",
      "0.061847432433678684\n",
      "0.07059140609904008\n",
      "0.1211303337610549\n",
      "0.07172813678793923\n",
      "0.05593734157850083\n",
      "0.049005055257414325\n",
      "0.050317033309075825\n",
      "0.0\n",
      "[999, 999, 999, 0.05119393640181146, 0.04801154983757769, 0.08663193802960224, 0.061847432433678684, 0.07059140609904008, 0.1211303337610549, 0.07172813678793923, 0.05593734157850083, 0.049005055257414325, 0.050317033309075825, 999]\n",
      "should delete 4\n",
      "0.0\n",
      "0.06950750730939279\n",
      "0.0\n",
      "0.05119393640181146\n",
      "0.04801154983757769\n",
      "0.08663193802960224\n",
      "0.061847432433678684\n",
      "0.07059140609904008\n",
      "0.1211303337610549\n",
      "0.07172813678793923\n",
      "0.05593734157850083\n",
      "0.049005055257414325\n",
      "0.050317033309075825\n",
      "0.0\n",
      "[999, 999, 999, 0.05119393640181146, 0.04801154983757769, 0.08663193802960224, 0.061847432433678684, 0.07059140609904008, 0.1211303337610549, 0.07172813678793923, 0.05593734157850083, 0.049005055257414325, 0.050317033309075825, 999]\n",
      "should delete 4\n",
      "0.0\n",
      "0.06950750730939279\n",
      "0.0\n",
      "0.05119393640181146\n",
      "0.04801154983757769\n",
      "0.08663193802960224\n",
      "0.061847432433678684\n",
      "0.07059140609904008\n",
      "0.1211303337610549\n",
      "0.07172813678793923\n",
      "0.05593734157850083\n",
      "0.049005055257414325\n",
      "0.050317033309075825\n",
      "0.0\n",
      "[999, 999, 999, 0.05119393640181146, 0.04801154983757769, 0.08663193802960224, 0.061847432433678684, 0.07059140609904008, 0.1211303337610549, 0.07172813678793923, 0.05593734157850083, 0.049005055257414325, 0.050317033309075825, 999]\n",
      "should delete 4\n",
      "0.0\n",
      "0.06950750730939279\n",
      "0.0\n",
      "0.05119393640181146\n",
      "0.04801154983757769\n",
      "0.08663193802960224\n",
      "0.061847432433678684\n",
      "0.07059140609904008\n",
      "0.1211303337610549\n",
      "0.07172813678793923\n",
      "0.05593734157850083\n",
      "0.049005055257414325\n",
      "0.050317033309075825\n",
      "0.0\n",
      "[999, 999, 999, 0.05119393640181146, 0.04801154983757769, 0.08663193802960224, 0.061847432433678684, 0.07059140609904008, 0.1211303337610549, 0.07172813678793923, 0.05593734157850083, 0.049005055257414325, 0.050317033309075825, 999]\n",
      "should delete 4\n",
      "12 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  santa clara , california\n",
      "0.0\n",
      "0.10635440415173414\n",
      "0.0\n",
      "0.02709021818923274\n",
      "0.033354472064793264\n",
      "0.054060375531233\n",
      "0.07778761702223805\n",
      "0.11151390230215312\n",
      "0.06517711108205443\n",
      "0.04338322749252762\n",
      "0.02986192358248964\n",
      "0.031532931659738826\n",
      "0.03171122049915862\n",
      "0.0\n",
      "[999, 999, 999, 0.02709021818923274, 0.033354472064793264, 0.054060375531233, 0.07778761702223805, 0.11151390230215312, 0.06517711108205443, 0.04338322749252762, 0.02986192358248964, 0.031532931659738826, 0.03171122049915862, 999]\n",
      "should delete 3\n",
      "0.0\n",
      "0.10635440415173414\n",
      "0.0\n",
      "0.02709021818923274\n",
      "0.033354472064793264\n",
      "0.054060375531233\n",
      "0.07778761702223805\n",
      "0.11151390230215312\n",
      "0.06517711108205443\n",
      "0.04338322749252762\n",
      "0.02986192358248964\n",
      "0.031532931659738826\n",
      "0.03171122049915862\n",
      "0.0\n",
      "[999, 999, 999, 0.02709021818923274, 0.033354472064793264, 0.054060375531233, 0.07778761702223805, 0.11151390230215312, 0.06517711108205443, 0.04338322749252762, 0.02986192358248964, 0.031532931659738826, 0.03171122049915862, 999]\n",
      "should delete 3\n",
      "0.0\n",
      "0.10635440415173414\n",
      "0.0\n",
      "0.02709021818923274\n",
      "0.033354472064793264\n",
      "0.054060375531233\n",
      "0.07778761702223805\n",
      "0.11151390230215312\n",
      "0.06517711108205443\n",
      "0.04338322749252762\n",
      "0.02986192358248964\n",
      "0.031532931659738826\n",
      "0.03171122049915862\n",
      "0.0\n",
      "[999, 999, 999, 0.02709021818923274, 0.033354472064793264, 0.054060375531233, 0.07778761702223805, 0.11151390230215312, 0.06517711108205443, 0.04338322749252762, 0.02986192358248964, 0.031532931659738826, 0.03171122049915862, 999]\n",
      "should delete 3\n",
      "0.0\n",
      "0.10635440415173414\n",
      "0.0\n",
      "0.02709021818923274\n",
      "0.033354472064793264\n",
      "0.054060375531233\n",
      "0.07778761702223805\n",
      "0.11151390230215312\n",
      "0.06517711108205443\n",
      "0.04338322749252762\n",
      "0.02986192358248964\n",
      "0.031532931659738826\n",
      "0.03171122049915862\n",
      "0.0\n",
      "[999, 999, 999, 0.02709021818923274, 0.033354472064793264, 0.054060375531233, 0.07778761702223805, 0.11151390230215312, 0.06517711108205443, 0.04338322749252762, 0.02986192358248964, 0.031532931659738826, 0.03171122049915862, 999]\n",
      "should delete 3\n",
      "0.0\n",
      "0.10635440415173414\n",
      "0.0\n",
      "0.02709021818923274\n",
      "0.033354472064793264\n",
      "0.054060375531233\n",
      "0.07778761702223805\n",
      "0.11151390230215312\n",
      "0.06517711108205443\n",
      "0.04338322749252762\n",
      "0.02986192358248964\n",
      "0.031532931659738826\n",
      "0.03171122049915862\n",
      "0.0\n",
      "[999, 999, 999, 0.02709021818923274, 0.033354472064793264, 0.054060375531233, 0.07778761702223805, 0.11151390230215312, 0.06517711108205443, 0.04338322749252762, 0.02986192358248964, 0.031532931659738826, 0.03171122049915862, 999]\n",
      "should delete 3\n",
      "13 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  super bowl l\n",
      "0.0\n",
      "0.0692118390759792\n",
      "0.1215941265096332\n",
      "0.0\n",
      "0.03478584417501457\n",
      "0.02884881312695345\n",
      "0.021093902308186724\n",
      "0.029415060303354435\n",
      "0.022242775390666183\n",
      "0.1189650444532604\n",
      "0.040411420385492336\n",
      "0.02165881710701138\n",
      "0.032230497312484445\n",
      "0.05864479614868158\n",
      "0.0\n",
      "[999, 999, 0.1215941265096332, 999, 0.03478584417501457, 0.02884881312695345, 0.021093902308186724, 0.029415060303354435, 0.022242775390666183, 0.1189650444532604, 0.040411420385492336, 0.02165881710701138, 0.032230497312484445, 0.05864479614868158, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.0692118390759792\n",
      "0.1215941265096332\n",
      "0.0\n",
      "0.03478584417501457\n",
      "0.02884881312695345\n",
      "0.021093902308186724\n",
      "0.029415060303354435\n",
      "0.022242775390666183\n",
      "0.1189650444532604\n",
      "0.040411420385492336\n",
      "0.02165881710701138\n",
      "0.032230497312484445\n",
      "0.05864479614868158\n",
      "0.0\n",
      "[999, 999, 0.1215941265096332, 999, 0.03478584417501457, 0.02884881312695345, 0.021093902308186724, 0.029415060303354435, 0.022242775390666183, 0.1189650444532604, 0.040411420385492336, 0.02165881710701138, 0.032230497312484445, 0.05864479614868158, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.0692118390759792\n",
      "0.1215941265096332\n",
      "0.0\n",
      "0.03478584417501457\n",
      "0.02884881312695345\n",
      "0.021093902308186724\n",
      "0.029415060303354435\n",
      "0.022242775390666183\n",
      "0.1189650444532604\n",
      "0.040411420385492336\n",
      "0.02165881710701138\n",
      "0.032230497312484445\n",
      "0.05864479614868158\n",
      "0.0\n",
      "[999, 999, 0.1215941265096332, 999, 0.03478584417501457, 0.02884881312695345, 0.021093902308186724, 0.029415060303354435, 0.022242775390666183, 0.1189650444532604, 0.040411420385492336, 0.02165881710701138, 0.032230497312484445, 0.05864479614868158, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.0692118390759792\n",
      "0.1215941265096332\n",
      "0.0\n",
      "0.03478584417501457\n",
      "0.02884881312695345\n",
      "0.021093902308186724\n",
      "0.029415060303354435\n",
      "0.022242775390666183\n",
      "0.1189650444532604\n",
      "0.040411420385492336\n",
      "0.02165881710701138\n",
      "0.032230497312484445\n",
      "0.05864479614868158\n",
      "0.0\n",
      "[999, 999, 0.1215941265096332, 999, 0.03478584417501457, 0.02884881312695345, 0.021093902308186724, 0.029415060303354435, 0.022242775390666183, 0.1189650444532604, 0.040411420385492336, 0.02165881710701138, 0.032230497312484445, 0.05864479614868158, 999]\n",
      "should delete 6\n",
      "0.0\n",
      "0.0692118390759792\n",
      "0.1215941265096332\n",
      "0.0\n",
      "0.03478584417501457\n",
      "0.02884881312695345\n",
      "0.021093902308186724\n",
      "0.029415060303354435\n",
      "0.022242775390666183\n",
      "0.1189650444532604\n",
      "0.040411420385492336\n",
      "0.02165881710701138\n",
      "0.032230497312484445\n",
      "0.05864479614868158\n",
      "0.0\n",
      "[999, 999, 0.1215941265096332, 999, 0.03478584417501457, 0.02884881312695345, 0.021093902308186724, 0.029415060303354435, 0.022242775390666183, 0.1189650444532604, 0.040411420385492336, 0.02165881710701138, 0.032230497312484445, 0.05864479614868158, 999]\n",
      "should delete 6\n",
      "14 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  2015\n",
      "0.0\n",
      "0.11528963567297269\n",
      "0.0\n",
      "0.042549314843667835\n",
      "0.030187515709876853\n",
      "0.013730303413820847\n",
      "0.02734949177702522\n",
      "0.009722907431194435\n",
      "0.12034072810144565\n",
      "0.02203076855007287\n",
      "0.022276866844299525\n",
      "0.029096245542314065\n",
      "0.03847016880138397\n",
      "0.0\n",
      "[999, 999, 999, 0.042549314843667835, 0.030187515709876853, 0.013730303413820847, 0.02734949177702522, 0.009722907431194435, 0.12034072810144565, 0.02203076855007287, 0.022276866844299525, 0.029096245542314065, 0.03847016880138397, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.11528963567297269\n",
      "0.0\n",
      "0.042549314843667835\n",
      "0.030187515709876853\n",
      "0.013730303413820847\n",
      "0.02734949177702522\n",
      "0.009722907431194435\n",
      "0.12034072810144565\n",
      "0.02203076855007287\n",
      "0.022276866844299525\n",
      "0.029096245542314065\n",
      "0.03847016880138397\n",
      "0.0\n",
      "[999, 999, 999, 0.042549314843667835, 0.030187515709876853, 0.013730303413820847, 0.02734949177702522, 0.009722907431194435, 0.12034072810144565, 0.02203076855007287, 0.022276866844299525, 0.029096245542314065, 0.03847016880138397, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.11528963567297269\n",
      "0.0\n",
      "0.042549314843667835\n",
      "0.030187515709876853\n",
      "0.013730303413820847\n",
      "0.02734949177702522\n",
      "0.009722907431194435\n",
      "0.12034072810144565\n",
      "0.02203076855007287\n",
      "0.022276866844299525\n",
      "0.029096245542314065\n",
      "0.03847016880138397\n",
      "0.0\n",
      "[999, 999, 999, 0.042549314843667835, 0.030187515709876853, 0.013730303413820847, 0.02734949177702522, 0.009722907431194435, 0.12034072810144565, 0.02203076855007287, 0.022276866844299525, 0.029096245542314065, 0.03847016880138397, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.11528963567297269\n",
      "0.0\n",
      "0.042549314843667835\n",
      "0.030187515709876853\n",
      "0.013730303413820847\n",
      "0.02734949177702522\n",
      "0.009722907431194435\n",
      "0.12034072810144565\n",
      "0.02203076855007287\n",
      "0.022276866844299525\n",
      "0.029096245542314065\n",
      "0.03847016880138397\n",
      "0.0\n",
      "[999, 999, 999, 0.042549314843667835, 0.030187515709876853, 0.013730303413820847, 0.02734949177702522, 0.009722907431194435, 0.12034072810144565, 0.02203076855007287, 0.022276866844299525, 0.029096245542314065, 0.03847016880138397, 999]\n",
      "should delete 7\n",
      "0.0\n",
      "0.11528963567297269\n",
      "0.0\n",
      "0.042549314843667835\n",
      "0.030187515709876853\n",
      "0.013730303413820847\n",
      "0.02734949177702522\n",
      "0.009722907431194435\n",
      "0.12034072810144565\n",
      "0.02203076855007287\n",
      "0.022276866844299525\n",
      "0.029096245542314065\n",
      "0.03847016880138397\n",
      "0.0\n",
      "[999, 999, 999, 0.042549314843667835, 0.030187515709876853, 0.013730303413820847, 0.02734949177702522, 0.009722907431194435, 0.12034072810144565, 0.02203076855007287, 0.022276866844299525, 0.029096245542314065, 0.03847016880138397, 999]\n",
      "should delete 7\n",
      "15 个完成了\n",
      "c_handle测试完成-> cascading_result.txt\n",
      "my answer is  2016\n",
      "0.0\n",
      "0.10847892438927918\n",
      "0.0\n",
      "0.054937731351174336\n",
      "0.03969684488091415\n",
      "0.05382080213616545\n",
      "0.10861594958511336\n",
      "0.02612406486517462\n",
      "0.19392569390257697\n",
      "0.04685349892349915\n",
      "0.04063624135411274\n",
      "0.023728756894204086\n",
      "0.06744827277596302\n",
      "0.0\n",
      "[999, 999, 999, 0.054937731351174336, 0.03969684488091415, 0.05382080213616545, 0.10861594958511336, 0.02612406486517462, 0.19392569390257697, 0.04685349892349915, 0.04063624135411274, 0.023728756894204086, 0.06744827277596302, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.10847892438927918\n",
      "0.0\n",
      "0.054937731351174336\n",
      "0.03969684488091415\n",
      "0.05382080213616545\n",
      "0.10861594958511336\n",
      "0.02612406486517462\n",
      "0.19392569390257697\n",
      "0.04685349892349915\n",
      "0.04063624135411274\n",
      "0.023728756894204086\n",
      "0.06744827277596302\n",
      "0.0\n",
      "[999, 999, 999, 0.054937731351174336, 0.03969684488091415, 0.05382080213616545, 0.10861594958511336, 0.02612406486517462, 0.19392569390257697, 0.04685349892349915, 0.04063624135411274, 0.023728756894204086, 0.06744827277596302, 999]\n",
      "should delete 11\n",
      "0.0\n",
      "0.10847892438927918\n",
      "0.0\n",
      "0.054937731351174336\n",
      "0.03969684488091415\n",
      "0.05382080213616545\n",
      "0.10861594958511336\n",
      "0.02612406486517462\n",
      "0.19392569390257697\n",
      "0.04685349892349915\n",
      "0.04063624135411274\n",
      "0.023728756894204086\n",
      "0.06744827277596302\n",
      "0.0\n",
      "[999, 999, 999, 0.054937731351174336, 0.03969684488091415, 0.05382080213616545, 0.10861594958511336, 0.02612406486517462, 0.19392569390257697, 0.04685349892349915, 0.04063624135411274, 0.023728756894204086, 0.06744827277596302, 999]\n",
      "should delete 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22397/1190337631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcascading_muti_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0mC_f1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0mC_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22397/1190337631.py\u001b[0m in \u001b[0;36mcascading_muti_pre\u001b[0;34m(cycle_num, question, text, s_answer, pro_keep, pro_next)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         tokens, attributions, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n\u001b[0m\u001b[1;32m    677\u001b[0m             question, retext)\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22397/1190337631.py\u001b[0m in \u001b[0;36mpred_explain\u001b[0;34m(question, text)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_qt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     all_tokens, attributions_start_sum = explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask,\n\u001b[0m\u001b[1;32m    419\u001b[0m                                                  start_scores, end_scores, ground_truth, all_tokens, )\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22397/1190337631.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mlig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerIntegratedGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquad_pos_forward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     attributions_start, delta_start = lig.attribute(inputs=input_ids,\n\u001b[0m\u001b[1;32m    203\u001b[0m                                                     \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                                     additional_forward_args=(\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         attributions = self.ig.attribute.__wrapped__(  # type: ignore\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0minputs_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minternal_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             attributions = _batch_attribution(\n\u001b[0m\u001b[1;32m    274\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/attr/_utils/batching.py\u001b[0m in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mstep_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_step_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         current_attr = attr_method._attribute(\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sizes_and_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# flattening grads so that we can multilpy it with step-size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# calling contiguous to avoid `memory whole` problems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         scaled_grads = [\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xai/lib/python3.8/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    359\u001b[0m         scaled_grads = [\n\u001b[1;32m    360\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import difflib\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "# replace <PATd:/spofrte/modeH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "# load model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "\"\"\"++++++++++++++++++这几个函数是计算f1 score 数值的，代码是抄的，千万不能改！+++++++++++++++++\"\"\"\n",
    "\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "\n",
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "\n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "\n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "\n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example -\n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "\n",
    "    return gold_answers\n",
    "\n",
    "\n",
    "\"\"\"+++++++++++++++++++++++++++++++++++\"\"\"\n",
    "\n",
    "\n",
    "def string_similar(s1, s2):\n",
    "    return difflib.SequenceMatcher(None, s1, s2).quick_ratio()\n",
    "\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids, attention_mask=attention_mask, )\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "ref_token_id = tokenizer.pad_token_id  # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id  # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id  # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)  # * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=token_type_ids,\n",
    "                                                 position_ids=position_ids)\n",
    "\n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "def predict_qt(question, text):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id,\n",
    "                                                                cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = '13'\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, \\\n",
    "                                       token_type_ids=token_type_ids, \\\n",
    "                                       position_ids=position_ids, \\\n",
    "                                       attention_mask=attention_mask)\n",
    "\n",
    "    #print('Question: ', question)\n",
    "    #print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1]))\n",
    "    return input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens,\n",
    "\n",
    "\n",
    "def explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores,\n",
    "            ground_truth, all_tokens, ):\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, model.bert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "                                                    baselines=ref_input_ids,\n",
    "                                                    additional_forward_args=(\n",
    "                                                        token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                    internal_batch_size=4,\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids,\n",
    "                                                additional_forward_args=(\n",
    "                                                    token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                internal_batch_size=4,\n",
    "                                                return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_start_sum,\n",
    "        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "        torch.argmax(start_scores),\n",
    "        torch.argmax(start_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_start_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_start)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_end_sum,\n",
    "        torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "        torch.argmax(end_scores),\n",
    "        torch.argmax(end_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_end_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_end)\n",
    "    # print(all_tokens)\n",
    "    #print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "    #viz.visualize_text([start_position_vis])\n",
    "\n",
    "    #print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "\n",
    "    #print(\"attributions_start_sum:   \", len(attributions_start_sum))\n",
    "    # print(\"all tokens:    \", len(all_tokens))\n",
    "\n",
    "    return all_tokens, attributions_start_sum\n",
    "\n",
    "\n",
    "def get_posneg(all_tokens, attributions_start_sum):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "    for i, j in enumerate(attributions_start_sum):\n",
    "        if j > 0:\n",
    "            positive.append(i)\n",
    "            # print('positive:',j)\n",
    "        ##print(all_tokens[i])\n",
    "        elif j < 0:\n",
    "            negative.append(i)\n",
    "            # print('negative:',j)\n",
    "            # print(all_tokens[i])\n",
    "        elif j == 0:\n",
    "            neutral.append(i)\n",
    "\n",
    "    s_pos = ''\n",
    "    s_neg = ''\n",
    "\n",
    "    # print(len(attributions_start_sum))\n",
    "    # print(len(positive))\n",
    "    # print(len(negative))\n",
    "\n",
    "    for i in positive:\n",
    "        s_pos += all_tokens[i] + ' '\n",
    "    # print(\"positive :\", s_pos)\n",
    "    for i in negative:\n",
    "        s_neg += all_tokens[i] + ' '\n",
    "    # print(\"negative :\", s_neg)\n",
    "    return positive, negative, neutral\n",
    "\n",
    "\n",
    "def separate_sentence(all_tokens):\n",
    "    sentence = {}\n",
    "    temp = []\n",
    "    num = 0\n",
    "    for i in range(len(all_tokens)):\n",
    "        if all_tokens[i] == \",\" or all_tokens[i] == \".\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[CLS]\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[SEP]\":\n",
    "            sentence[num] = temp\n",
    "            num = num + 1\n",
    "            temp = [all_tokens[i]]\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        else:\n",
    "            temp.append(all_tokens[i])\n",
    "    return sentence\n",
    "def gaussian_scores(scores):\n",
    "    # 使用高斯滤波替换贡献:\n",
    "    old_contri = []\n",
    "    for i in scores.values():\n",
    "        old_contri.append(i)\n",
    "\n",
    "    gaussian_contri = gaussian_filter(old_contri, sigma=5)\n",
    "    gaussin_scores = {}\n",
    "    index = 0\n",
    "    for i, j in scores.items():\n",
    "        gaussin_scores[i] = gaussian_contri[index]\n",
    "        index = index + 1\n",
    "    return gaussin_scores\n",
    "\n",
    "def get_sence_score(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    sentence_score = []\n",
    "    for k, v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores = {}\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = abs(attributions_start_sum[i].item())\n",
    "        except:\n",
    "            pass\n",
    "    #scores = gaussian_scores(scores)\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight += scores[word]\n",
    "        if len(j)!=0:\n",
    "            print(sum_weight/len(j))\n",
    "            sentence_score.append(sum_weight/len(j))\n",
    "        # print(sum_weight)\n",
    "    return sentence_score\n",
    "def get_sence_gaussianscore(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = []\n",
    "    for k, v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores = {}\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "    scores = gaussian_scores(scores)\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight += scores[word]\n",
    "        delete_sentence.append(sum_weight)\n",
    "        # print(sum_weight)\n",
    "    return delete_sentence\n",
    "\n",
    "def get_delete(sentence):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = {}\n",
    "    for k, v in sentence.items():\n",
    "        # print(k,':',v)\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    # print(sentence_value)\n",
    "    scores = {}\n",
    "    # print(attributions_start_sum[0].item())\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            weight = 0\n",
    "\n",
    "            sum_weight += scores[word]\n",
    "            delete_sentence[i] = sum_weight\n",
    "    return delete_sentence\n",
    "\n",
    "\n",
    "def delete_sentence(sentence, li_delete_sentence):\n",
    "    for i, j in sentence.items():\n",
    "        if i in li_delete_sentence:\n",
    "            sentence[i] = []\n",
    "        else:\n",
    "            pass\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def rebuild_sentence(ori_sentence):\n",
    "    rebuild_str = \"\"\n",
    "    for i, j in ori_sentence.items():\n",
    "        for word in j:\n",
    "            rebuild_str += word\n",
    "            rebuild_str += \" \"\n",
    "    return rebuild_str\n",
    "\n",
    "\n",
    "def pred_explain(question, text):\n",
    "    input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens, = predict_qt(question, text)\n",
    "\n",
    "    all_tokens, attributions_start_sum = explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask,\n",
    "                                                 start_scores, end_scores, ground_truth, all_tokens, )\n",
    "\n",
    "    end_score = float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "    start_score = float(torch.max(torch.softmax(start_scores[0], dim=0)))\n",
    "\n",
    "    return all_tokens, attributions_start_sum, end_score, start_score, [torch.argmax(start_scores), torch.argmax(\n",
    "        end_scores) + 1], start_scores, end_scores\n",
    "\n",
    "\n",
    "def max_min(x, y, z):\n",
    "    max = min = x\n",
    "    i = 1\n",
    "    if y > max:\n",
    "        max = y\n",
    "        i = 2\n",
    "    else:\n",
    "        min = y\n",
    "    if z > max:\n",
    "        max = z\n",
    "        i = 3\n",
    "    else:\n",
    "        min = z\n",
    "    return (i)\n",
    "\n",
    "def analysis(f1, acc_s, acc_e, sun):\n",
    "    plt.plot(range(len(f1)), f1, \"--bo\", label=\"f1 score\")\n",
    "    plt.show()\n",
    "    plt.plot(range(len(acc_s)), acc_s)\n",
    "    plt.plot(range(len(acc_e)), acc_e)\n",
    "    plt.plot(range(len(sun)), sun)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cycle_prediction(cycle_num, question, text, s_answer):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(text,\n",
    "                                                                                                              question)\n",
    "\n",
    "    f1 = []\n",
    "    acc_s = []\n",
    "    acc_e = []\n",
    "    sun = []\n",
    "    ans = []\n",
    "    second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    second_answer = re.sub(r' ##', '', second_answer)\n",
    "    f1_score = compute_f1(second_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = rebuild_text(all_tokens, attributions_start_sum)\n",
    "\n",
    "        all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "        reanswer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        # print(start_acc, end_acc)\n",
    "        second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        # print(\"my answer is \", second_answer)\n",
    "        ans.append(second_answer)\n",
    "        # print(start_acc, end_acc)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "        pos_contri = 0\n",
    "        neg_contri = 0\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(acc_s)):\n",
    "        sun.append((acc_s[i] + acc_e[i]) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "def cascading_rebuild_text(all_tokens, attributions_start_sum):\n",
    "\n",
    "    li_sep = []\n",
    "    min_sensocer = 999\n",
    "    li_symbol = []\n",
    "    min_index = 999\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    sentence_score = get_sence_score(sentence, attributions_start_sum)\n",
    "    guassian_score = get_sence_gaussianscore(sentence, attributions_start_sum)\n",
    "\n",
    "    for i in range(len(sentence_score)):\n",
    "        if sentence_score[i] == 0:\n",
    "            li_symbol.append(i)\n",
    "\n",
    "    for i in li_symbol:\n",
    "        guassian_score[i] == 0\n",
    "    for i in range(len(guassian_score)):\n",
    "        if sentence_score[i] < min_sensocer and sentence_score[i] != 0:\n",
    "            min_sensocer = sentence_score[i]\n",
    "            min_index = i\n",
    "    print(\"should delete\", min_index, min_sensocer)\n",
    "\n",
    "    # temp = []\n",
    "    # for i in sentence_score:\n",
    "    #     temp.append(abs(i))\n",
    "    # sentence[sentence_score.index(min(temp))] = ''\n",
    "\n",
    "\n",
    "    sentence[min_index] = ''#删除贡献最小的句子\n",
    "    sentence[1] = ''#删除问题\n",
    "    retext = \"\"\n",
    "    for i, j in sentence.items():\n",
    "        for words in j:\n",
    "            retext = retext + words + \" \"\n",
    "    #这是清楚 ## 等模型引入的字符串\n",
    "    for m in re.finditer(r\"SEP\", retext):\n",
    "        li_sep.append(m.start())\n",
    "        li_sep.append(m.end())\n",
    "    retext = retext[li_sep[1] + 1: li_sep[2] - 1]\n",
    "    retext = re.sub(r' ##', '', retext)\n",
    "    return retext\n",
    "def av_cascading_rebuild_text(all_tokens, attributions_start_sum):\n",
    "\n",
    "    li_sep = []\n",
    "    li_symbol = []\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    sentence_score = get_sence_score(sentence, attributions_start_sum)\n",
    "   \n",
    "    \"\"\"0和问题得贡献置为999\"\"\"\n",
    "    sentence_score[1] = 999\n",
    "    while min(sentence_score) == 0:\n",
    "        sentence_score[sentence_score.index(min(sentence_score))] = 999\n",
    "    print(\"should delete\", sentence_score.index(min(sentence_score)))\n",
    "    # temp = []\n",
    "    # for i in sentence_score:\n",
    "    #     temp.append(abs(i))\n",
    "    # sentence[sentence_score.index(min(temp))] = ''\n",
    "\n",
    "\n",
    "    sentence[sentence_score.index(min(sentence_score))] = ''#删除贡献最小的句子\n",
    "    sentence[1] = ''#删除问题\n",
    "    retext = \"\"\n",
    "    for i, j in sentence.items():\n",
    "        for words in j:\n",
    "            retext = retext + words + \" \"\n",
    "    #这是清楚 ## 等模型引入的字符串\n",
    "    for m in re.finditer(r\"SEP\", retext):\n",
    "        li_sep.append(m.start())\n",
    "        li_sep.append(m.end())\n",
    "    retext = retext[li_sep[1] + 1: li_sep[2] - 1]\n",
    "    retext = re.sub(r' ##', '', retext)\n",
    "    return retext\n",
    "def cascading_min(data, min_id):\n",
    "    print(\"threshold : \", min_id)\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == 0:\n",
    "            data[i] = 999\n",
    "    d = {}\n",
    "    li_min = []\n",
    "    if min_id == 0:  # 设定一个空字典\n",
    "        for i, v in enumerate(data):  # 利用函数enumerate列出lt的每个元素下标i和元素v\n",
    "            d[v] = i  # 把v作为字典的键，v对应的值是i\n",
    "        data.sort()  # 运用sort函数对lt元素排\n",
    "        y = data[min_id]  # 此时lt中第二小的下标是1，求出对应的元素就是字典对应的键\n",
    "        return [d[y]]\n",
    "    if min_id != 0:\n",
    "        for i, v in enumerate(data):  # 利用函数enumerate列出lt的每个元素下标i和元素v\n",
    "            d[v] = i  # 把v作为字典的键，v对应的值是i\n",
    "        data.sort()  # 运用sort函数对lt元素排\n",
    "        try:\n",
    "            for i in range(min_id):\n",
    "                li_min.append(d[data[i]])  # 此时lt中第二小的下标是1，求出对应的元素就是字典对应的键\n",
    "        except:\n",
    "            pass\n",
    "        return li_min\n",
    "\n",
    "\n",
    "\n",
    "def independ_rebuild_text(all_tokens, attributions_start_sum, threshold):\n",
    "\n",
    "    li_sep = []\n",
    "    min_sensocer = 999\n",
    "    li_symbol = []\n",
    "    min_index = []\n",
    "    sentence = separate_sentence(all_tokens)\n",
    "    sentence_score = get_sence_score(sentence, attributions_start_sum)\n",
    "\n",
    "    min_index = cascading_min(sentence_score, threshold)\n",
    "    print(\"should delete : \", min_index)\n",
    "\n",
    "\n",
    "    # temp = []\n",
    "    # for i in sentence_score:\n",
    "    #     temp.append(abs(i))\n",
    "    # sentence[sentence_score.index(min(temp))] = ''\n",
    "\n",
    "    for i in min_index:\n",
    "        sentence[i] = \"\"#删除贡献最小的句子\n",
    "    sentence[1] = ''#删除问题\n",
    "    retext = \"\"\n",
    "    for i, j in sentence.items():\n",
    "        for words in j:\n",
    "            retext = retext + words + \" \"\n",
    "    #这是清楚 ## 等模型引入的字符串\n",
    "    for m in re.finditer(r\"SEP\", retext):\n",
    "        li_sep.append(m.start())\n",
    "        li_sep.append(m.end())\n",
    "    if len(li_sep) > 2:\n",
    "        retext = retext[li_sep[1] + 1: li_sep[2] - 1]\n",
    "    retext = re.sub(r' ##', '', retext)\n",
    "    return retext\n",
    "def independ_muti_pre(cycle_num, question, text, s_answer, pro_keep, pro_next):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(question, text)\n",
    "\n",
    "    first_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    first_answer = re.sub(r' ##', '', first_answer)\n",
    "    print(\"my answer is \", first_answer)\n",
    "    ans = []\n",
    "    acc_s= []\n",
    "    acc_e = []\n",
    "    f1 = []\n",
    "    sun = []\n",
    "    f1_score = compute_f1(first_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    acc_s.append(start_acc)\n",
    "    acc_e.append(end_acc)\n",
    "    sun.append((start_acc+end_acc)/2)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = independ_rebuild_text(all_tokens, attributions_start_sum, loop)\n",
    "\n",
    "\n",
    "        tokens, attributions, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "\n",
    "        second_answer = ' '.join(tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        ans.append(second_answer)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "        sun.append((start_acc + end_acc) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "\n",
    "def cascading_muti_pre(cycle_num, question, text, s_answer, pro_keep, pro_next):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(question, text)\n",
    "\n",
    "    first_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    first_answer = re.sub(r' ##', '', first_answer)\n",
    "    print(\"my answer is \", first_answer)\n",
    "    ans = []\n",
    "    acc_s= []\n",
    "    acc_e = []\n",
    "    f1 = []\n",
    "    sun = []\n",
    "    f1_score = compute_f1(first_answer, s_answer)\n",
    "    f1.append(f1_score)\n",
    "    acc_s.append(start_acc)\n",
    "    acc_e.append(end_acc)\n",
    "    sun.append((start_acc+end_acc)/2)\n",
    "    for loop in range(cycle_num):\n",
    "        retext = av_cascading_rebuild_text(all_tokens, attributions_start_sum)\n",
    "\n",
    "\n",
    "        tokens, attributions, start_acc, end_acc, an_index, start_scores, end_scores = pred_explain(\n",
    "            question, retext)\n",
    "\n",
    "        second_answer = ' '.join(tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        ans.append(second_answer)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "\n",
    "        f1_score = compute_f1(second_answer, s_answer)\n",
    "        f1.append(f1_score)\n",
    "        sun.append((start_acc + end_acc) / 2)\n",
    "    return f1, acc_s, acc_e, sun\n",
    "\n",
    "def write_fil(filname, f1, acc_s, acc_e, sun):\n",
    "    c_handle = {}\n",
    "    c_handle[\"f1\"] = f1\n",
    "    c_handle[\"forword_pro\"] = acc_s\n",
    "    c_handle[\"backword_pro\"] = acc_e\n",
    "    c_handle[\"sun_pro\"] = sun\n",
    "    print(\"c_handle测试完成->\", filname)\n",
    "    with open(filname, \"a\")as f:\n",
    "        f.write(str(c_handle) + \"\\r\\n\")\n",
    "\n",
    "datasets = load_dataset('squad')\n",
    "C_f1 = []\n",
    "C_accs = []\n",
    "C_acce = []\n",
    "C_sun = []\n",
    "\n",
    "i_f1 = []\n",
    "i_accs = []\n",
    "i_acce = []\n",
    "i_sun = []\n",
    "c_handle = {}\n",
    "\n",
    "i_handle = {}\n",
    "\n",
    "# for i in range(len(datasets['validation'])):\n",
    "for i in range(20):\n",
    "    text = datasets['validation'][i]['context']\n",
    "    question = datasets['validation'][i]['question']\n",
    "    answers = datasets['validation'][i]['answers']\n",
    "    f1, acc_s, acc_e, sun = cascading_muti_pre(5, question, text, answers['text'][0], 0.9, 0.7)\n",
    "    C_f1.append(f1)\n",
    "    C_accs.append(acc_s)\n",
    "    C_acce.append(acc_e)\n",
    "    C_sun.append(sun)\n",
    "\n",
    "\n",
    "    print(i, \"个完成了\")\n",
    "    write_fil(\"cascading_result.txt\", f1, acc_s, acc_e, sun)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c133999f0ce8d3c4aa177894441247ff4efac3487be3c31d2df0852d80fcfe89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('xai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
