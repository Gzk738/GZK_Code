{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a767a0c3-1350-480e-ad51-db361ffaa6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "import difflib\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# replace <PATd:/spofrte/modeH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "# load model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "    \n",
    "def string_similar(s1, s2):\n",
    "    return difflib.SequenceMatcher(None, s1, s2).quick_ratio()\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids, attention_mask=attention_mask, )\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values\n",
    "\n",
    "fig = plt.figure()  \n",
    "fig.set_size_inches(8, 6)\n",
    "\n",
    "ref_token_id = tokenizer.pad_token_id  # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id  # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id  # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
    "                    [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)  # * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "\n",
    "\n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                    position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=token_type_ids,\n",
    "                                                 position_ids=position_ids)\n",
    "\n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "def predict_qt(question, text):\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id,\n",
    "                                                                cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = '13'\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, \\\n",
    "                                       token_type_ids=token_type_ids, \\\n",
    "                                       position_ids=position_ids, \\\n",
    "                                       attention_mask=attention_mask)\n",
    "\n",
    "    print('Question: ', question)\n",
    "    print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1]))\n",
    "    return input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens,\n",
    "\n",
    "\n",
    "def explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores,\n",
    "            ground_truth, all_tokens, ):\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, model.bert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "                                                    baselines=ref_input_ids,\n",
    "                                                    additional_forward_args=(\n",
    "                                                        token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                    internal_batch_size=4,\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids,\n",
    "                                                additional_forward_args=(\n",
    "                                                    token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                internal_batch_size=4,\n",
    "                                                return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_start_sum,\n",
    "        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "        torch.argmax(start_scores),\n",
    "        torch.argmax(start_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_start_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_start)\n",
    "\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "        attributions_end_sum,\n",
    "        torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "        torch.argmax(end_scores),\n",
    "        torch.argmax(end_scores),\n",
    "        str(ground_truth),\n",
    "        attributions_end_sum.sum(),\n",
    "        all_tokens,\n",
    "        delta_end)\n",
    "    #print(all_tokens)\n",
    "    print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "    viz.visualize_text([start_position_vis])\n",
    "\n",
    "    print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "\n",
    "    print(\"attributions_start_sum:   \", len(attributions_start_sum))\n",
    "    #print(\"all tokens:    \", len(all_tokens))\n",
    "\n",
    "    return all_tokens, attributions_start_sum\n",
    "\n",
    "\n",
    "def get_posneg(all_tokens, attributions_start_sum):\n",
    "    positive = []\n",
    "    negative = []\n",
    "    neutral = []\n",
    "    for i, j in enumerate(attributions_start_sum):\n",
    "        if j > 0:\n",
    "            positive.append(i)\n",
    "            # print('positive:',j)\n",
    "        ##print(all_tokens[i])\n",
    "        elif j < 0:\n",
    "            negative.append(i)\n",
    "            # print('negative:',j)\n",
    "            # print(all_tokens[i])\n",
    "        elif j == 0:\n",
    "            neutral.append(i)\n",
    "\n",
    "    s_pos = ''\n",
    "    s_neg = ''\n",
    "\n",
    "    # print(len(attributions_start_sum))\n",
    "    # print(len(positive))\n",
    "    # print(len(negative))\n",
    "\n",
    "    for i in positive:\n",
    "        s_pos += all_tokens[i] + ' '\n",
    "    #print(\"positive :\", s_pos)\n",
    "    for i in negative:\n",
    "        s_neg += all_tokens[i] + ' '\n",
    "    #print(\"negative :\", s_neg)\n",
    "    return positive, negative, neutral\n",
    "\n",
    "\n",
    "def separate_sentence(all_tokens):\n",
    "    sentence = {}\n",
    "    temp = []\n",
    "    num = 0\n",
    "    for i in range(len(all_tokens)):\n",
    "        if all_tokens[i] == \",\" or all_tokens[i] == \".\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[CLS]\":\n",
    "            temp.append(all_tokens[i])\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        elif all_tokens[i] == \"[SEP]\":\n",
    "            sentence[num] = temp\n",
    "            num = num + 1\n",
    "            temp = [all_tokens[i]]\n",
    "            sentence[num] = temp\n",
    "            temp = []\n",
    "            num = num + 1\n",
    "        else:\n",
    "            temp.append(all_tokens[i])\n",
    "    return sentence\n",
    "def get_sence_score(sentence, attributions_start_sum):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value=[]\n",
    "    delete_sentence = []\n",
    "    for k,v in sentence.items():\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    scores={}\n",
    "\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]]=attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            sum_weight +=  scores[word]\n",
    "        delete_sentence.append(sum_weight)\n",
    "        #print(sum_weight)\n",
    "    return delete_sentence\n",
    "\n",
    "def get_delete(sentence):\n",
    "    weight = 0\n",
    "    sum_weight = 0\n",
    "    sentence_value = []\n",
    "    delete_sentence = {}\n",
    "    for k, v in sentence.items():\n",
    "        # print(k,':',v)\n",
    "        for i in v:\n",
    "            sentence_value.append(i)\n",
    "    #print(sentence_value)\n",
    "    scores = {}\n",
    "    # print(attributions_start_sum[0].item())\n",
    "\n",
    "    for i in range(len(attributions_start_sum)):\n",
    "        try:\n",
    "            scores[sentence_value[i]] = attributions_start_sum[i].item()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i, j in sentence.items():\n",
    "        sum_weight = 0\n",
    "        for word in j:\n",
    "            weight = 0\n",
    "\n",
    "            sum_weight += scores[word]\n",
    "            delete_sentence[i] = sum_weight\n",
    "    return delete_sentence\n",
    "\n",
    "\n",
    "def delete_sentence(sentence, li_delete_sentence):\n",
    "    for i, j in sentence.items():\n",
    "        if i in li_delete_sentence:\n",
    "            sentence[i] = []\n",
    "        else:\n",
    "            pass\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def rebuild_sentence(ori_sentence):\n",
    "    rebuild_str = \"\"\n",
    "    for i, j in ori_sentence.items():\n",
    "        for word in j:\n",
    "            rebuild_str += word\n",
    "            rebuild_str += \" \"\n",
    "    return rebuild_str\n",
    "\n",
    "\n",
    "def pred_explain(question, text):\n",
    "    input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask, start_scores, end_scores, ground_truth, all_tokens, = predict_qt(\n",
    "        text, question)\n",
    "\n",
    "    all_tokens, attributions_start_sum = explain(input_ids, ref_input_ids, token_type_ids, position_ids, attention_mask,\n",
    "                                                 start_scores, end_scores, ground_truth, all_tokens, )\n",
    "\n",
    "    end_score = float(torch.max(torch.softmax(end_scores[0], dim=0)))\n",
    "    start_score = float(torch.max(torch.softmax(start_scores[0], dim=0)))\n",
    "    return all_tokens, attributions_start_sum, end_score, start_score, [torch.argmax(start_scores), torch.argmax(end_scores)+1], start_scores, end_scores\n",
    "def max_min(x, y, z):\n",
    "    max = min = x\n",
    "    i = 1\n",
    "    if y > max:\n",
    "        max = y\n",
    "        i = 2\n",
    "    else:\n",
    "        min = y\n",
    "    if z > max:\n",
    "        max = z\n",
    "        i =3\n",
    "    else:\n",
    "        min = z\n",
    "    return (i)\n",
    "def cycle_prediction(cycle_num, question, text, s_answer):\n",
    "    all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores = pred_explain(text, question)\n",
    "    \n",
    "    \"\"\"如果答案对了，就退出循环\"\"\"\n",
    "    ans = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "    print(\"ans is\", torch.argmax(start_scores), torch.argmax(end_scores) + 1)\n",
    "    if string_similar(s_answer, ans) > 0.5:\n",
    "        print(\"预测个啥啊， 第一个是对的， 下一个！\")\n",
    "        return\n",
    "    print(\"这个答案不对，继续预测\")\n",
    "    acc_s = []\n",
    "    acc_e = []\n",
    "    sun = []\n",
    "    ans = []\n",
    "    \n",
    "    for loop in range(cycle_num):\n",
    "        sentence = separate_sentence(all_tokens)\n",
    "        sentence_score  = get_sence_score(sentence, attributions_start_sum)\n",
    "        min_sensocer = 999\n",
    "        min_index = 999\n",
    "        for i in range(len(sentence_score)):\n",
    "            if sentence_score[i] < min_sensocer and sentence_score[i] != 0:\n",
    "                min_sensocer = sentence_score[i]\n",
    "                min_index = i\n",
    "        #print(\"should delete\", min_index, min_sensocer)\n",
    "        sentence[min_index] = ''\n",
    "        sentence[1] = ''\n",
    "        retext = \"\"\n",
    "        for i, j in sentence.items():\n",
    "            for words in j:\n",
    "                retext = retext + words + \" \"\n",
    "        li_sep = []\n",
    "        for m in re.finditer(r\"SEP\", retext):\n",
    "            li_sep.append(m.start())\n",
    "            li_sep.append(m.end())\n",
    "        retext = retext[li_sep[1]+1: li_sep[2] -1]\n",
    "        retext = re.sub(r' ##', '', retext)\n",
    "\n",
    "\n",
    "\n",
    "        all_tokens, attributions_start_sum, start_acc, end_acc,  an_index, start_scores, end_scores= pred_explain(retext, question)\n",
    "        reanswer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        #print(start_acc, end_acc)\n",
    "        second_answer = ' '.join(all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "        second_answer = re.sub(r' ##', '', second_answer)\n",
    "        #print(\"my answer is \", second_answer)\n",
    "        ans.append(second_answer)\n",
    "        #print(start_acc, end_acc)\n",
    "        acc_s.append(start_acc)\n",
    "        acc_e.append(end_acc)\n",
    "        pos_contri = 0\n",
    "        neg_contri = 0\n",
    "        if string_similar(s_answer, second_answer) > 0.5:\n",
    "            break\n",
    "        \n",
    "\n",
    "        #print(acc_s, acc_e)\n",
    "        #print(acc_s, acc_e)\n",
    "    \"\"\"输出曲线\"\"\"\n",
    "    plt.plot(range(len(acc_s)), acc_s, label = 'start score')\n",
    "    plt.plot(range(len(acc_s)), acc_e, label = 'end score')\n",
    "    sun = []\n",
    "    for i in range(len(acc_s)):\n",
    "        sun.append((acc_s[i] + acc_e[i])/2)\n",
    "    print(sun)\n",
    "    plt.plot(range(len(acc_s)), sun, label = 'average')\n",
    "    plt.xlabel('Number of predictions')\n",
    "    plt.ylabel('Possibility')    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    \"\"\"\"获取最好的曲线并输出\"\"\"\n",
    "    max_start = 0\n",
    "    max_end = 0\n",
    "    max_ave = 0\n",
    "    for i in acc_s:\n",
    "        if i > max_start:\n",
    "            max_start = i\n",
    "    for j in acc_e:\n",
    "        if j > max_end:\n",
    "            max_end = i\n",
    "\n",
    "    for x in sun:\n",
    "        if x > max_ave:\n",
    "            max_ave = x\n",
    "\n",
    "    print(max_start ,max_end ,max_ave )\n",
    "\n",
    "\n",
    "    max_list = max_min(max_start, max_end, max_ave)\n",
    "    if max_list == 1:\n",
    "        plt.plot(range(len(acc_s)), acc_s, label = 'Possibility')\n",
    "        print(acc_s)\n",
    "    if max_list == 2:\n",
    "        plt.plot(range(len(acc_e)), acc_e, label = 'Possibility')\n",
    "        print(acc_e)\n",
    "    if max_list == 3:\n",
    "        plt.plot(range(len(sun)), sun, label = 'Possibility')\n",
    "        print(sun)\n",
    "\n",
    "    plt.xlabel('Number of predictions')\n",
    "    plt.ylabel('Possibility')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    for i in range(len(ans)):\n",
    "        print(ans[i])\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f36f0-c8fe-4de3-944f-7740476c31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"\"\"What was the amount of wins Knute Rockne attained at Notre Dame while head coach?\"\"\"\n",
    "\n",
    "\n",
    "answer = \"\"\"saint bernadette soubirous\"\"\"\n",
    "\n",
    "cycle_prediction(20, question, text, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed4ffa-cb17-43c3-a2d8-f42abbca6303",
   "metadata": {
    "tags": []
   },
   "source": [
    "{'id': '573387acd058e614000b5cb2', 'title': 'University_of_Notre_Dame', 'context': 'One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in 1925, and produced players such as George Gipp and the \"Four Horsemen\". Knute Rockne has the highest winning percentage (.881) in NCAA Division I/FBS football history. Rockne\\'s offenses employed the Notre Dame Box and his defenses ran a 7–2–2 scheme. The last game Rockne coached was on December 14, 1930 when he led a group of Notre Dame all-stars against the New York Giants in New York City.', 'question': 'What was the amount of wins Knute Rockne attained at Notre Dame while head coach?', 'answers': {'text': ['105'], 'answer_start': [204]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67974cab-0378-48a5-ae0f-bc8b4e176c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\Guo Zikun\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 573387acd058e614000b5cb5\n",
      "title University_of_Notre_Dame\n",
      "context One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in 1925, and produced players such as George Gipp and the \"Four Horsemen\". Knute Rockne has the highest winning percentage (.881) in NCAA Division I/FBS football history. Rockne's offenses employed the Notre Dame Box and his defenses ran a 7–2–2 scheme. The last game Rockne coached was on December 14, 1930 when he led a group of Notre Dame all-stars against the New York Giants in New York City.\n",
      "question In what year did the team lead by Knute Rockne win the Rose Bowl?\n",
      "answers {'text': ['1925'], 'answer_start': [354]}\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset('squad')\n",
    "\n",
    "for i, j in datasets['train'][100].items():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c7686a-9431-489d-8f44-be0ef50b96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n"
     ]
    }
   ],
   "source": [
    "a = \"One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in \"\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620bdae4-713d-47b0-9ca3-838e5a57bf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
